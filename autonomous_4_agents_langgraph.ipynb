{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ff70b7",
   "metadata": {},
   "source": [
    "# 4 Autonomous Research Agents ‚Äî LangGraph Agentic Graph\n",
    "\n",
    "**Architecture:** A single LangGraph executor node routes dynamically at runtime.  \n",
    "The flow is **never hard-coded** ‚Äî each agent decides `next_agent` in its output.\n",
    "\n",
    "| Agent | Role |\n",
    "|-------|------|\n",
    "| **Planner** | Understands goal, breaks into sub-questions, decides who runs next |\n",
    "| **Researcher** | RAG retrieval from vector DB, grounded answers + sources |\n",
    "| **Evaluator** | Scores confidence, detects gaps, routes to Expansion or END |\n",
    "| **Expansion** | ArXiv search (online mode) **or** idea generation only (workspace mode) |\n",
    "\n",
    "---\n",
    "\n",
    "## Two Operating Modes\n",
    "\n",
    "| Mode | `search_mode` value | Expansion behaviour |\n",
    "|------|--------------------|--------------------|\n",
    "| **Online** | `\"online\"` | Searches ArXiv, downloads & indexes new papers, loops back to Researcher |\n",
    "| **Workspace-only** | `\"workspace\"` | Never touches the internet ‚Äî uses only local PDFs already indexed |\n",
    "\n",
    "Set `SEARCH_MODE` in **Section 11** before running.\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "  ‚îÇ          LangGraph StateGraph           ‚îÇ\n",
    "  ‚îÇ                                         ‚îÇ\n",
    "  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ\n",
    "  ‚îÇ   ‚îÇ       agent_executor         ‚îÇ‚óÑ‚îÄ‚îê   ‚îÇ\n",
    "  ‚îÇ   ‚îÇ  (single dynamic dispatcher) ‚îÇ  ‚îÇ   ‚îÇ\n",
    "  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ   ‚îÇ\n",
    "  ‚îÇ              ‚îÇ                      ‚îÇ   ‚îÇ\n",
    "  ‚îÇ         route(state)                ‚îÇ   ‚îÇ\n",
    "  ‚îÇ         /         \\                 ‚îÇ   ‚îÇ\n",
    "  ‚îÇ      LOOP          END              ‚îÇ   ‚îÇ\n",
    "  ‚îÇ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "  AGENT_REGISTRY maps name ‚Üí function at runtime:\n",
    "    'Planner'    ‚Üí planner_agent(state)\n",
    "    'Researcher' ‚Üí researcher_agent(state)\n",
    "    'Evaluator'  ‚Üí evaluator_agent(state)\n",
    "    'Expansion'  ‚Üí expansion_agent(state)   ‚Üê behaviour controlled by search_mode\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88b4da2",
   "metadata": {},
   "source": [
    "## 0. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b6442b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q langgraph langchain langchain-core langchain-community langchain-groq \\\n",
    "#               langchain-openai langchain-chroma chromadb openai \\\n",
    "#               pypdf arxiv python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c28b3ba",
   "metadata": {},
   "source": [
    "## 1. Imports & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afbfd5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM ready: llama-3.3-70b-versatile\n",
      "üìÅ Workspace: /workspaces/research-hub/agent_workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, TypedDict\n",
    "\n",
    "import arxiv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ‚îÄ‚îÄ LLM (Groq ‚Äî swap for any LangChain ChatModel) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "llm = None\n",
    "try:\n",
    "    from langchain_groq import ChatGroq\n",
    "    _key = os.getenv(\"GROQ_API_KEY\", \"\")\n",
    "    if _key:\n",
    "        llm = ChatGroq(\n",
    "            model=os.getenv(\"GROQ_MODEL\", \"llama-3.3-70b-versatile\"),\n",
    "            temperature=0.1,\n",
    "            api_key=_key,\n",
    "        )\n",
    "        print(\"‚úÖ LLM ready:\", llm.model_name)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  GROQ_API_KEY not set ‚Äî agents will use fallback logic\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  langchain-groq not installed ‚Äî agents will use fallback logic\")\n",
    "\n",
    "# ‚îÄ‚îÄ Workspace directories ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "WORK_DIR   = Path(\"./agent_workspace\")\n",
    "PDF_DIR    = WORK_DIR / \"papers_local\"       # drop your PDFs here\n",
    "ARXIV_DIR  = WORK_DIR / \"papers_arxiv\"       # Expansion agent saves here\n",
    "CHROMA_DIR = WORK_DIR / \"chroma_db\"\n",
    "\n",
    "for d in [WORK_DIR, PDF_DIR, ARXIV_DIR, CHROMA_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"üìÅ Workspace:\", WORK_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c34cc",
   "metadata": {},
   "source": [
    "## 2. Shared Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee05c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helpers ready\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ JSON parsing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def _parse_json(text: str) -> dict:\n",
    "    t = text.strip()\n",
    "    if t.startswith(\"```\"):\n",
    "        t = t.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "    return json.loads(t)\n",
    "\n",
    "\n",
    "def _llm_json(prompt: str, fallback: dict) -> dict:\n",
    "    \"\"\"Call the LLM and parse JSON output. Return fallback on any error.\"\"\"\n",
    "    if llm is None:\n",
    "        return fallback\n",
    "    try:\n",
    "        raw = llm.invoke([HumanMessage(content=prompt)]).content\n",
    "        return _parse_json(raw)\n",
    "    except Exception as e:\n",
    "        print(f\"  [LLM parse error] {e}\")\n",
    "        return fallback\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ Vector DB (Chroma + OpenAI embeddings) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def build_vectordb():\n",
    "    \"\"\"Instantiate (or reuse) the persistent Chroma vector store.\"\"\"\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    try:\n",
    "        from langchain_chroma import Chroma\n",
    "    except ImportError:\n",
    "        from langchain_community.vectorstores import Chroma  # type: ignore\n",
    "\n",
    "    emb = OpenAIEmbeddings(model=os.getenv(\"OPENAI_EMBED_MODEL\", \"text-embedding-3-small\"))\n",
    "    vdb = Chroma(\n",
    "        collection_name=\"autonomous_4agents\",\n",
    "        embedding_function=emb,\n",
    "        persist_directory=str(CHROMA_DIR),\n",
    "    )\n",
    "    return vdb\n",
    "\n",
    "\n",
    "def ingest_dirs(vdb, dirs: list[Path]) -> int:\n",
    "    \"\"\"Load all PDFs from dirs, chunk them, and upsert into the vector store.\"\"\"\n",
    "    pdfs = [p for d in dirs for p in d.rglob(\"*.pdf\")]\n",
    "    docs: list[Document] = []\n",
    "    for p in pdfs:\n",
    "        try:\n",
    "            pages = PyPDFLoader(str(p)).load()\n",
    "            for pg in pages:\n",
    "                pg.metadata[\"source\"] = str(p)\n",
    "            docs.extend(pages)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not docs:\n",
    "        return 0\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1_200, chunk_overlap=200)\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    ids = [\n",
    "        hashlib.md5(\n",
    "            f\"{c.metadata.get('source')}|{c.metadata.get('page',-1)}|{c.page_content[:80]}\"\n",
    "            .encode()\n",
    "        ).hexdigest()\n",
    "        for c in chunks\n",
    "    ]\n",
    "    if chunks:\n",
    "        vdb.add_documents(chunks, ids=ids)\n",
    "    return len(chunks)\n",
    "\n",
    "\n",
    "def retrieve(vdb, query: str, k: int = 8) -> list[Document]:\n",
    "    return vdb.similarity_search(query, k=k)\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ ArXiv helper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def arxiv_expand(query: str, max_results: int = 4) -> list[Path]:\n",
    "    \"\"\"Search ArXiv, download PDFs, return file paths.\"\"\"\n",
    "    client = arxiv.Client(page_size=max_results, delay_seconds=3, num_retries=3)\n",
    "    search = arxiv.Search(\n",
    "        query=query, max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.Relevance,\n",
    "    )\n",
    "    saved = []\n",
    "    for r in client.results(search):\n",
    "        try:\n",
    "            fp = r.download_pdf(dirpath=str(ARXIV_DIR), filename=f\"{r.get_short_id()}.pdf\")\n",
    "            saved.append(Path(fp))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return saved\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helpers ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d36827",
   "metadata": {},
   "source": [
    "## 3. State Schema\n",
    "\n",
    "One `TypedDict` carries everything through the graph.  \n",
    "`current_agent` tells the executor **which** agent to run next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2698e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict, total=False):\n",
    "    # ‚îÄ‚îÄ Core ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    goal: str                   # research question\n",
    "    vdb: Any                    # Chroma vector store (passed by reference)\n",
    "    current_agent: str          # which agent is active RIGHT NOW\n",
    "    next_agent: str             # where to route after this agent\n",
    "    iterations: int             # expansion loop counter\n",
    "    max_iterations: int         # hard cap on expansion loops\n",
    "\n",
    "    # ‚îÄ‚îÄ Mode ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    search_mode: str            # \"online\"  ‚Üí ArXiv search allowed\n",
    "                                # \"workspace\" ‚Üí use only local/already-indexed PDFs\n",
    "\n",
    "    # ‚îÄ‚îÄ Per-agent outputs (accumulated in state) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    planner:    dict            # {subtasks, next_agent}\n",
    "    researcher: dict            # {answer, sources, next_agent}\n",
    "    evaluator:  dict            # {confidence, missing_aspects, next_agent}\n",
    "    expansion:  dict            # {query, papers_downloaded, chunks_added, saturated, ideas, mode}\n",
    "\n",
    "    # ‚îÄ‚îÄ Final outputs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    final_answer: str\n",
    "    final_sources: list\n",
    "    future_ideas: list\n",
    "    trace: list                 # execution log [\"Planner ‚Üí Researcher\", ...]\n",
    "\n",
    "    # ‚îÄ‚îÄ Insufficiency tracking ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    insufficient_data: bool     # True when the system could not gather enough evidence\n",
    "    insufficiency_reason: str   # human-readable explanation of why data was insufficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd276948",
   "metadata": {},
   "source": [
    "## 4. Agent 1 ‚Äî Planner (Lightweight Brain)\n",
    "\n",
    "- Understands the research goal  \n",
    "- Breaks it into sub-questions  \n",
    "- Decides who runs next (always `Researcher`)  \n",
    "- **Does NOT search** ‚Äî pure reasoning only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac817b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner_agent(state: AgentState) -> dict:\n",
    "    goal = state[\"goal\"]\n",
    "    print(f\"  üß† [Planner] Goal: {goal[:80]}...\")\n",
    "\n",
    "    fallback = {\n",
    "        \"subtasks\": [\"model architecture\", \"training datasets\", \"evaluation benchmarks\"],\n",
    "        \"next_agent\": \"Researcher\",\n",
    "    }\n",
    "    prompt = f\"\"\"You are the Planner Agent.\n",
    "Research goal: {goal}\n",
    "\n",
    "Your job:\n",
    "1. Understand the goal deeply.\n",
    "2. Break it into 3-5 focused sub-questions.\n",
    "3. Do NOT search ‚Äî only plan.\n",
    "4. Always route next to Researcher.\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "{{\"subtasks\": [\"sub-question 1\", \"sub-question 2\", \"...\"], \"next_agent\": \"Researcher\"}}\"\"\"\n",
    "\n",
    "    out = _llm_json(prompt, fallback)\n",
    "    subtasks = out.get(\"subtasks\", fallback[\"subtasks\"])\n",
    "    if not isinstance(subtasks, list):\n",
    "        subtasks = fallback[\"subtasks\"]\n",
    "\n",
    "    print(f\"  üß† [Planner] Subtasks: {subtasks}\")\n",
    "    return {\n",
    "        \"planner\": {\"subtasks\": subtasks, \"next_agent\": \"Researcher\"},\n",
    "        \"next_agent\": \"Researcher\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "41e4d915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'planner': {'subtasks': ['Systematic literature review on late disease detection factors and diagnostic errors.',\n",
       "   'Characterize diagnostic errors by modality and error type (missed, delayed, cognitive bias).',\n",
       "   'Assemble and anonymize a multi-institution dataset capturing time-to-diagnosis, misdiagnoses, and outcomes.',\n",
       "   'Develop and validate AI-assisted screening and triage models to flag potential diseases earlier.',\n",
       "   'Design clinician decision-support tools to standardize workflows and reduce cognitive bias.',\n",
       "   'Build a scalable data analysis pipeline for EMR, imaging, and lab data to accelerate insights.',\n",
       "   'Implement data interoperability with FHIR/HL7 and standard ontologies to speed data sharing.',\n",
       "   'Prototype telemedicine and mobile health interventions to expand access in underserved areas.',\n",
       "   'Pilot interventions in rural/low-resource settings to measure impact on time-to-diagnosis and error rates.',\n",
       "   'Create privacy-preserving analytics (federated learning, differential privacy) to enable rapid analysis.',\n",
       "   'Develop real-time dashboards and alert systems to monitor diagnostic timeliness and data throughput.',\n",
       "   'Develop risk stratification models to identify patients at high risk for late diagnosis.',\n",
       "   'Assess regulatory, ethical, and equity implications and formulate actionable recommendations.'],\n",
       "  'next_agent': 'Researcher'},\n",
       " 'next_agent': 'Researcher'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AgentState = {\n",
    "    \"goal\":           \"\"\"‚úî Late disease detection\n",
    "‚úî Diagnostic human errors\n",
    "‚úî Slow medical data analysis\n",
    "‚úî Limited healthcare accessibility\"\"\",\n",
    "    \"vdb\":            vdb,\n",
    "    \"search_mode\":    \"workspace\",\n",
    "    \"current_agent\":  \"Planner\",\n",
    "    \"next_agent\":     \"Planner\",\n",
    "    \"iterations\":     0,\n",
    "    \"max_iterations\": 3,\n",
    "    \"future_ideas\":   [],\n",
    "    \"trace\":          [],\n",
    "}\n",
    "planner_agent(AgentState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f53e74f",
   "metadata": {},
   "source": [
    "## 5. Agent 2 ‚Äî Researcher (RAG Agent)\n",
    "\n",
    "- Retrieves evidence from the Chroma vector DB  \n",
    "- Generates a grounded answer with source citations  \n",
    "- Routes to `Evaluator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4c27e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Simple grounded RAG prompt\n",
    "researcher_prompt = ChatPromptTemplate.from_template(\n",
    "#     \"\"\"You are a Researcher Agent.\n",
    "\n",
    "# Goal:\n",
    "# {goal}\n",
    "\n",
    "# Subtasks:\n",
    "# {subtasks}\n",
    "\n",
    "# Use ONLY the provided context to evaluate feasibility.\n",
    "\n",
    "# <context>\n",
    "# {context}\n",
    "# </context>\n",
    "\n",
    "# Instructions:\n",
    "# - Determine whether the stated research goal can realistically be solved using the data, methods, experiments, or resources described in the context.\n",
    "# - Evaluate if the provided methodology, data quality, scope, and approach are sufficient to achieve the goal.\n",
    "# - If the goal appears achievable based on the context, clearly state that the research is feasible and explain why.\n",
    "# - If the goal cannot be fully achieved, identify the specific limitations, missing components, unrealistic assumptions, or methodological gaps.\n",
    "# - You may reason about logical consistency and practical feasibility based strictly on the given context.\n",
    "# - Do NOT use external knowledge.\n",
    "# - Do NOT assume information not present in the context.\n",
    "\n",
    "# If the context does not contain enough information to determine feasibility,\n",
    "# respond with: \"Insufficient information to assess feasibility.\"\n",
    "\n",
    "# Answer:\n",
    "# \"\"\"\n",
    "\"\"\"You are a Researcher Agent.\n",
    "\n",
    "Goal:\n",
    "{goal}\n",
    "\n",
    "Subtasks:\n",
    "{subtasks}\n",
    "\n",
    "Use ONLY the provided context.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Determine whether the research goal can realistically be solved using the data, methodology, analysis, or approach described in the context.\n",
    "- Evaluate feasibility, logical consistency, and completeness of the approach.\n",
    "- If results or evidence are provided, base your conclusion strictly on that evidence.\n",
    "- If no explicit results are provided, reason based on whether the described methods and data are sufficient to achieve the stated goal.\n",
    "- If the approach appears sufficient, state that the research goal is achievable and explain why.\n",
    "- If the approach appears insufficient, clearly identify the gaps (e.g., missing data, weak methodology, unclear evaluation, lack of validation, etc.).\n",
    "- Do NOT use external knowledge.\n",
    "- Do NOT assume information not present in the context.\n",
    "\n",
    "If the context does not contain enough information to assess feasibility,\n",
    "respond with: \"Insufficient information to determine feasibility.\"\n",
    "\n",
    "Answer:\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def researcher_agent(state: dict) -> dict:\n",
    "    goal = state[\"goal\"]\n",
    "    subtasks = state.get(\"planner\", {}).get(\"subtasks\", [])\n",
    "    vdb = state[\"vdb\"]\n",
    "\n",
    "    # Retrieve for main goal + each subtask\n",
    "    retriever = vdb.as_retriever(search_kwargs={\"k\": 6})\n",
    "    docs = []\n",
    "\n",
    "    docs.extend(retriever.invoke(goal))\n",
    "    for subtask in subtasks:\n",
    "        docs.extend(retriever.invoke(subtask))\n",
    "\n",
    "    # Build context\n",
    "    context = \"\\n\\n\".join(d.page_content for d in docs)\n",
    "    print(context)\n",
    "    # Run LLM chain\n",
    "    chain = researcher_prompt | llm\n",
    "    result = chain.invoke({\n",
    "        \"goal\": goal,\n",
    "        \"subtasks\": subtasks,\n",
    "        \"context\": context\n",
    "    })\n",
    "\n",
    "    answer = result.content \n",
    "\n",
    "    sources = [\n",
    "        {\n",
    "            \"source\": d.metadata.get(\"source\"),\n",
    "            \"page\": d.metadata.get(\"page\")\n",
    "        }\n",
    "        for d in docs\n",
    "    ]\n",
    "\n",
    "    # Return both legacy and final keys for compatibility across notebook cells\n",
    "    return {\n",
    "        \"researcher\": {\n",
    "            \"answer\": answer,\n",
    "            \"sources\": sources,\n",
    "            \"next_agent\": \"Evaluator\",\n",
    "        },\n",
    "        \"final_answer\": answer,\n",
    "        \"final_sources\": sources,\n",
    "        \"next_agent\": \"Evaluator\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7517681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"goal\":           \"\"\"‚úî Late disease detection\n",
    "‚úî Diagnostic human errors\n",
    "‚úî Slow medical data analysis\n",
    "‚úî Limited healthcare accessibility\"\"\",\n",
    "    \"vdb\":            vdb,\n",
    "    \"search_mode\":    \"workspace\",\n",
    "    \"current_agent\":  \"Planner\",\n",
    "    \"next_agent\":     \"Planner\",\n",
    "    \"iterations\":     0,\n",
    "    \"max_iterations\": 3,\n",
    "    \"future_ideas\":   [],\n",
    "    \"trace\":          [],'planner': {'subtasks': ['Systematic literature review on late disease detection factors and diagnostic errors.',\n",
    "   'Characterize diagnostic errors by modality and error type (missed, delayed, cognitive bias).',\n",
    "   'Assemble and anonymize a multi-institution dataset capturing time-to-diagnosis, misdiagnoses, and outcomes.',\n",
    "   'Develop and validate AI-assisted screening and triage models to flag potential diseases earlier.',\n",
    "   'Design clinician decision-support tools to standardize workflows and reduce cognitive bias.',\n",
    "   'Build a scalable data analysis pipeline for EMR, imaging, and lab data to accelerate insights.',\n",
    "   'Implement data interoperability with FHIR/HL7 and standard ontologies to speed data sharing.',\n",
    "   'Prototype telemedicine and mobile health interventions to expand access in underserved areas.',\n",
    "   'Pilot interventions in rural/low-resource settings to measure impact on time-to-diagnosis and error rates.',\n",
    "   'Create privacy-preserving analytics (federated learning, differential privacy) to enable rapid analysis.',\n",
    "   'Develop real-time dashboards and alert systems to monitor diagnostic timeliness and data throughput.',\n",
    "   'Develop risk stratification models to identify patients at high risk for late diagnosis.',\n",
    "   'Assess regulatory, ethical, and equity implications and formulate actionable recommendations.'],\n",
    "  'next_agent': 'Researcher'},\n",
    " 'next_agent': 'Researcher'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f8dd0ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Artificial Intelligence to Improve Early\n",
      "Disease Detection\n",
      "Abstract: Early detection of diseases such as cancer and diabetes significantly improves patient\n",
      "survival rates. Traditional diagnostic systems often rely on manual analysis, which can be slow and\n",
      "prone to human error. This research explores how Artificial Intelligence (AI) can assist in early\n",
      "disease detection using machine learning models.\n",
      "Introduction: Healthcare systems generate large volumes of medical data daily. Analyzing this data\n",
      "manually is challenging and time-consuming. AI systems can process complex datasets efficiently\n",
      "and identify patterns that may not be visible to human experts.\n",
      "Problem Statement: Many diseases are detected at later stages due to slow diagnostic procedures,\n",
      "human error, and limited access to medical specialists. Late diagnosis increases treatment costs\n",
      "and reduces survival probability.\n",
      "Objective: The objective of this research is to develop an AI-based predictive system that improves\n",
      "early detection accuracy and reduces diagnostic time.\n",
      "Methodology: Medical datasets are collected and preprocessed. Machine learning algorithms are\n",
      "\n",
      "early detection accuracy and reduces diagnostic time.\n",
      "Methodology: Medical datasets are collected and preprocessed. Machine learning algorithms are\n",
      "trained on the data to identify disease-related patterns. Model performance is evaluated using\n",
      "accuracy and recall metrics.\n",
      "Results: The AI model demonstrated improved diagnostic accuracy and faster analysis compared\n",
      "to traditional methods.\n",
      "Conclusion: AI-based early detection systems can support healthcare professionals by improving\n",
      "speed and accuracy of diagnosis. These systems act as decision-support tools rather than\n",
      "replacements for doctors.\n",
      "\n",
      "become the primary medium of documentation, clinicians spend substan-\n",
      "tial time on data entry, yet the resulting information, collected in part to\n",
      "enable billing and administrative workflows and in part to support clinical\n",
      "care and longitudinal analysis, remains difficult to synthesize during brief pa-\n",
      "tient encounters. In addition, EHR data span both structured elements (e.g.,\n",
      "2\n",
      "\n",
      "LLM baselines are warranted. Finally, external generalizability remains to\n",
      "be proven; site effects, referral patterns, surgical technique and perioperative\n",
      "care, medication adherence, patient psychology, priming effects for survey\n",
      "responses are all considerations that may shift feature distributions.\n",
      "Clinical relevance.Even with these constraints,‚âà85%accuracy with trans-\n",
      "parent explanations is meaningful for preoperative counseling. Errors are not\n",
      "equivalent clinically: false negatives (predicting non-benefit when benefit is\n",
      "likely) may delay effective surgery, while false positives may expose a pa-\n",
      "tient to operative risk with limited expected gain. Our framework supports\n",
      "threshold tuning and individualized decision curves, enabling clinicians to\n",
      "select operating points aligned with patient preferences and risk tolerance.\n",
      "The interactive visualizations help communicate why the recommendation\n",
      "was made and how it might change under alternative assumptions.\n",
      "Future directions.We outline several priorities to translate these findings:\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "\n",
      "assist users, and ensure medication adherence. With a focus  \n",
      "on improving healthcare accessibility and quality, the system \n",
      "integrated smart pill dispensers for monitoring and enhancing \n",
      "medication adherence , offering great potential in revolution - \n",
      "izing healthcare services. Ahamed explores the application \n",
      "of IoT and Machine Learning in Personalized Healthcare  \n",
      "(PH) to enhance disease management and intervention. IoT \n",
      "sensor devices and wearables collect patien t data, which is \n",
      "analyzed using AI and ML techniques for disease prediction \n",
      "and patient self -management. Challenges include biased data \n",
      "collection, outdated training datasets, and privacy concerns. \n",
      "The integration of IoT and ML in PH faces issues such as data \n",
      "transmission reliability and biased training datasets, impacting \n",
      "diagnostic accuracy. Addressing these challenges is crucial for \n",
      "improving personalized healthcare systems. Khurana imple - \n",
      "ments a Smart Healthcare System using IoT sensors to enhance \n",
      "patient care in hospitals. The system utilizes Ultrasonic and IR \n",
      "Proximity Sensors connected to an Arduino Uno for automated \n",
      "IV fluid level monitoring and patient alarm system. The liter -\n",
      "\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "preserving training. Also, include other surgery specific and patient\n",
      "psychological factors, other outcomes of relevance for decision making.\n",
      "2.Learning under imbalance:integrate calibrated re-weighting, adopt\n",
      "techniques like SMOTE/ADASYN/mixup, and generative augmenta-\n",
      "tion with clinical plausibility checks; evaluate minority-aware metrics\n",
      "prospectively.\n",
      "3.Temporal/external validation:perform temporal splits, external\n",
      "site validation, and pre-registered prospective studies; assess domain\n",
      "shift and transportability.\n",
      "4.Better targets and calibration:model continuous and time-to-\n",
      "eventendpoints; reportBrierscore/ECE;applytemperature/Plattcali-\n",
      "bration; usedecision-curveanalysistoquantifynetbenefitacrossthresh-\n",
      "olds.\n",
      "5.Uncertainty and reliability:add Bayesian/post-hoc uncertainty\n",
      "quantification, conformal prediction, and reject-option policies to flag\n",
      "cases for multidisciplinary review.\n",
      "6.Individualized treatment benefit:move beyond outcome predic-\n",
      "tion to estimate conditional treatment effects (uplift models, causal\n",
      "\n",
      "Using Artificial Intelligence to Improve Early\n",
      "Disease Detection\n",
      "Abstract: Early detection of diseases such as cancer and diabetes significantly improves patient\n",
      "survival rates. Traditional diagnostic systems often rely on manual analysis, which can be slow and\n",
      "prone to human error. This research explores how Artificial Intelligence (AI) can assist in early\n",
      "disease detection using machine learning models.\n",
      "Introduction: Healthcare systems generate large volumes of medical data daily. Analyzing this data\n",
      "manually is challenging and time-consuming. AI systems can process complex datasets efficiently\n",
      "and identify patterns that may not be visible to human experts.\n",
      "Problem Statement: Many diseases are detected at later stages due to slow diagnostic procedures,\n",
      "human error, and limited access to medical specialists. Late diagnosis increases treatment costs\n",
      "and reduces survival probability.\n",
      "Objective: The objective of this research is to develop an AI-based predictive system that improves\n",
      "early detection accuracy and reduces diagnostic time.\n",
      "Methodology: Medical datasets are collected and preprocessed. Machine learning algorithms are\n",
      "\n",
      "II. LITERATURE REVIEW \n",
      "A framework was proposed by Silva et al. [6] for auto - \n",
      "matically producing systematic literature reviews. They have \n",
      "focused on four technical steps: Searching, Screening, Map - \n",
      "ping, a nd Synthesizing. In response to a specific inquiry, \n",
      "extensive searches are conducted to find as much relevant \n",
      "research as feasible, involving looking through reference lists, \n",
      "scouring internet databases, and reviewing published materials. \n",
      "Screening reduces the search scope by limiting the collection \n",
      "to only the papers pertinent to a particular review, aiming \n",
      "to highlight important findings and facts that could influence \n",
      "policy. Mapping is used to comprehend research activity in \n",
      "a particular area, involve stakeholders, and define priorities \n",
      "concerning the review emphasis. Synthesizing integrates data \n",
      "from numerous sources and provides an overview of the \n",
      "outcomes. The formulation of research questions, reporting \n",
      "phase, and peer review are some steps that are also discussed \n",
      "for the composition of systematic literature reviews. \n",
      "Peer-reviewed publications are growing exponentially with \n",
      "the rapid development of science. Therefore, Yuan et al.\n",
      "\n",
      "early detection accuracy and reduces diagnostic time.\n",
      "Methodology: Medical datasets are collected and preprocessed. Machine learning algorithms are\n",
      "trained on the data to identify disease-related patterns. Model performance is evaluated using\n",
      "accuracy and recall metrics.\n",
      "Results: The AI model demonstrated improved diagnostic accuracy and faster analysis compared\n",
      "to traditional methods.\n",
      "Conclusion: AI-based early detection systems can support healthcare professionals by improving\n",
      "speed and accuracy of diagnosis. These systems act as decision-support tools rather than\n",
      "replacements for doctors.\n",
      "\n",
      "Rapid Review and Semi-Structured Interviews. Rapid Review \n",
      "emphasizes decision-making procedures for resolving issues, \n",
      "difficulties, and challenges that software engineers encounter \n",
      "in their daily work. Semi-structured interviews are used \n",
      "to explore researchers‚Äô experiences, challenges, strategies, \n",
      "strengths, weaknesses of Systematic Literature Review tools, \n",
      "and requirements for effective support in software engineering. \n",
      "Jaspers et al. [9] focused on the use of machine learning \n",
      "techniques for automation of literature reviews and systematic \n",
      "reviews. They have outlined the pros and cons of different \n",
      "machine-learning techniques. The process of automating the \n",
      "literature review was elaborately discussed. The paper lacks \n",
      "practical validation across diverse domains and detailed in- \n",
      "sights. \n",
      "A concise overview of automated literature reviews was \n",
      "presented by Tauchert et. al. [10] They have emphasized the \n",
      "potential for automation in various stages of the systematic \n",
      "review process. The paper discusses the importance of in - \n",
      "tegrating computational techniques to streamline tasks such  \n",
      "as searching, screening, extraction, and synthesis.  It also ac -\n",
      "\n",
      "for the composition of systematic literature reviews. \n",
      "Peer-reviewed publications are growing exponentially with \n",
      "the rapid development of science. Therefore, Yuan et al. \n",
      "[7] have explored the use of machine learning techniques, \n",
      "natural language generation, multi -document summarization, \n",
      "and multi-objective optimization for automating scientific re - \n",
      "viewing. They have discussed the generation of comprehensive \n",
      "reviews and noted the limitations of constructive feedback \n",
      "compared to human -written reviews. The models used in this \n",
      "research are not yet fully capable of automating Literature \n",
      "Reviews and they require human reviewers. \n",
      "A comprehensive analysis of existing tools for systematic \n",
      "literature reviews was done by Karakan et al. [8]. They have \n",
      "explored the potential for automation in various phases of the \n",
      "review process, highlighting the need for a holistic tool de- \n",
      "sign to address researchers‚Äô challenges effectively. They have \n",
      "discussed two methodologies to accomplish their research: \n",
      "Rapid Review and Semi-Structured Interviews. Rapid Review \n",
      "emphasizes decision-making procedures for resolving issues, \n",
      "difficulties, and challenges that software engineers encounter\n",
      "\n",
      "enhancing the effectiveness and applicability of the developed \n",
      "system tool. More functionality can be added to the Graphical \n",
      "User Interface such as model options, output size, etc. More \n",
      "models such as Bert, Gemini, and LLaMA can be utilized to \n",
      "find better results. \n",
      "[6] da Silva Ju¬¥nior EM, Dutra ML. A roadmap toward the automatic  \n",
      "composition of systematic literature reviews. Iberoamerican Journal of  \n",
      "Science Measurement and Communication. 2021 Jul 27. \n",
      "[7] Yuan W, Liu P, Neubig G. Can we au tomate scientific reviewing?.  \n",
      "Journal of Artificial Intelligence Research. 2022 Sep 29;75:171-212. \n",
      "[8] Karakan B, Wagner S, Bogner J. Tool support for systematic literature  \n",
      "reviews: Analyzing existing solutions and the potential for automation  \n",
      "(Doctoral dissertation, University of Stuttgart). \n",
      "[9] Jaspers S, De Troyer E, Aerts M. Machine learning techniques for the  \n",
      "automation of literature reviews and systematic reviews in EFSA. EFSA \n",
      "Supporting Publications. 2018 Jun;15(6):1427E. \n",
      "[10] Tauchert C, Bender M, Mesbah N, Buxm ann P. Towards an integrative  \n",
      "approach for automated literature reviews using machine learning.\n",
      "\n",
      "portunities for improving our framework.\n",
      "‚Ä¢ SEA Error (24.5%):As the ‚Äúbrain‚Äù of the\n",
      "iterative process, failures in the Strategic Evi-\n",
      "dence Assessment module are particularly im-\n",
      "pactful. These errors were significantly more\n",
      "prevalent in complex, multi-hop datasets like\n",
      "MuSiQue, HotpotQA, and 2WikiMultihopQA.\n",
      "The most common subtypes were: (i) Faulty\n",
      "Analysis of Evidence, where the SEA module\n",
      "failed to make a correct logical inference from\n",
      "the provided documents (e.g., misinterpreting\n",
      "complex genealogical relationships); and (ii)\n",
      "Premature Sufficiency Judgment, where the\n",
      "logic incorrectly concluded that the gathered\n",
      "evidence was complete, thus halting the re-\n",
      "finement loop too early.\n",
      "‚Ä¢ Query Logic Failures (12.0% combined):\n",
      "This group includes errors from the initial\n",
      "query processing stages. Query Decompo-\n",
      "sition Errors (9.0%) were the most common,\n",
      "often stemming from an inability to challenge\n",
      "flawed premises within the user‚Äôs question\n",
      "(e.g., processing a query with a historical\n",
      "anachronism) or generating overly broad sub-\n",
      "queries. Query Refinement (1.5%) and Ev-\n",
      "idence Filtering Errors (1.5%) were exceed-\n",
      "Figure 5: Task-Dependent Distribution of Failure\n",
      "\n",
      "complex, leading to reasoning errors,'or'The filtering model\n",
      "may be poorly calibrated for short documents').>\",\n",
      "\"suggested_improvement\": \"<Propose a concrete, actionable\n",
      "solution to fix or mitigate this specific type of error in the\n",
      "future. (e.g.,'Simplify the SEA prompt by removing the persona\n",
      "and focusing on a checklist,'or'Fine-tune the reranker with\n",
      "more examples of this type').>\"\n",
      "}\n",
      "\"\"\"\n",
      "\n",
      "centrated in the final two stages. Generation\n",
      "Failures emerged as the most dominant error\n",
      "category, accounting for a significant majority\n",
      "of all cases (54.9%). Retrieval Failures were\n",
      "the second most common at 27.9%. Errors in\n",
      "the upstream control flow were comparatively\n",
      "rare: Query Decomposition Errors accounted\n",
      "for 9.0%, Evidence Filtering Errors for 5.7%,\n",
      "and Structured Evidence Assessment (SEA)\n",
      "Errors for 2.5%. Notably, we observed no in-\n",
      "stances of Query Refinement Error, indicating\n",
      "that once an information gap is surfaced, the\n",
      "refinement module generally succeeds in tar-\n",
      "geting it.\n",
      "Generation F ailures (54.9%). Represent-\n",
      "ing over half of all errors, this category is\n",
      "unequivocally the primary bottleneck in the\n",
      "F ARSIQA architecture. These failures occur\n",
      "when the system successfully retrieves and fil-\n",
      "ters the correct evidentiary documents but\n",
      "fails to synthesize them into a factually accu-\n",
      "rate answer. We identified several recurring\n",
      "root causes:\n",
      "‚Ä¢ Flawed Logical Inference: The model\n",
      "struggles with reasoning tasks that re-\n",
      "quire understanding implicit relation-\n",
      "ships, particularly with cyclical concepts\n",
      "or complex relational chains.\n",
      "‚Ä¢ Misinterpretation of Question In-\n",
      "\n",
      "anachronism) or generating overly broad sub-\n",
      "queries. Query Refinement (1.5%) and Ev-\n",
      "idence Filtering Errors (1.5%) were exceed-\n",
      "Figure 5: Task-Dependent Distribution of Failure\n",
      "Modes. The analysis highlights a strong correlation\n",
      "between task complexity and the primary failure bot-\n",
      "tleneck. For the factoid-centric TriviaQA, Retrieval\n",
      "Failures are dominant (47%). Conversely, for complex\n",
      "multi-hop reasoning datasets like MuSiQue, HotpotQA,\n",
      "and 2WikiMultihopQA, the burden shifts towards rea-\n",
      "soning, with SEA Errors becoming a major failure cate-\n",
      "gory (28-32%). This trend validates the critical role of\n",
      "the strategic reasoning component (SEA) for success-\n",
      "fully navigating multi-step queries.\n",
      "ingly rare, suggesting that these architectural\n",
      "components are relatively robust.\n",
      "Dataset-Specific Error DistributionsWhile the\n",
      "aggregate view is informative, Figure 5 reveals\n",
      "that the distribution of failure modes is highly de-\n",
      "pendent on the nature of the task. For fact-based,\n",
      "single-hop datasets like TriviaQA, failures are over-\n",
      "whelmingly concentrated in the Retrieval stage\n",
      "(47%). However, as query complexity increases in\n",
      "multi-hop datasets (MuSiQue, HotpotQA, 2Wiki-\n",
      "\n",
      "process by low-quality retrievals [125]. When high-quality information is un-\n",
      "available, these mechanisms facilitate appropriate abstention behavior and\n",
      "graceful degradation [126].\n",
      "Table 8.2: Retrieval Quality Mechanisms Comparison\n",
      "Mechanism\n",
      "Accuracy\n",
      "Improvement\n",
      "Hallucination\n",
      "Reduction\n",
      "Implementation\n",
      "Effort Scalability\n",
      "Single\n",
      "Confidence\n",
      "Threshold\n",
      "Moderate Moderate Low High\n",
      "Multi-signal\n",
      "Scoring\n",
      "High High Medium Medium\n",
      "38\n",
      "\n",
      "Analysis of 200 error samples reveals a primary split\n",
      "between Component-Level Failures (63.5%) and Ar-\n",
      "chitectural Failures (36.5%). While architectural logic\n",
      "offers direct avenues for refinement, the majority of\n",
      "errors stem from the inherent limitations of the founda-\n",
      "tional retrieval and generation models, identifying them\n",
      "as the principal bottleneck for the FAIR-RAG system.\n",
      "(i.e., the retriever and the generator LLM), and (2)\n",
      "Architectural Failures, which are specific to the\n",
      "decision-making logic of the FAIR-RAG frame-\n",
      "work itself (i.e., Query Decomposition, Filtering,\n",
      "Refinement, and SEA).\n",
      "This distinction is critical for understanding the\n",
      "system‚Äôs bottlenecks. As shown in Figure 4, a sig-\n",
      "nificant majority of errors (63.5%) are Component-\n",
      "Level, originating from the foundational tools our\n",
      "system is built upon. The remaining 36.5% are\n",
      "Architectural, offering direct targets for refining\n",
      "FAIR-RAG‚Äôs internal logic. This distribution un-\n",
      "derscores a key insight: while FAIR-RAG‚Äôs itera-\n",
      "tive process is designed to mitigate the weaknesses\n",
      "of its components, the performance of these base\n",
      "components remains the primary limiting factor in\n",
      "overall system accuracy.\n",
      "\n",
      "(AFS),Asthma,Diabetes,Fibromyalgia) were recoded from text labels\n",
      "into integer categories via explicit dictionaries (for example,Female‚Üí0,\n",
      "Male‚Üí1 forSex;Employer provided‚Üí0,Medicare‚Üí1,Private‚Üí2,Canadian\n",
      "Medicare‚Üí3,Medicaid‚Üí4 forInsurance). Continuous baseline measures,\n",
      "such as theSNOT-22 Baseline Score,Baseline CT Score, andBaseline\n",
      "Endoscopy Score, were retained as numeric features. Where applicable,\n",
      "missing values were handled using simple domain-consistent rules (e.g., map-\n",
      "ping textual ‚ÄúNone‚Äù to a sentinel category for certain comorbidities); oth-\n",
      "erwise they were left for model-specific handling. After the encoding, we\n",
      "verified type consistency, and exported the encoded dataset for downstream\n",
      "train/test splitting and model fitting. This encoding scheme enables repro-\n",
      "ducible training across classifiers and avoids leakage from post-treatment or\n",
      "follow-up fields.\n",
      "Next, we partitioned the dataset into an80:20 train‚Äìtest splitus-\n",
      "ing stratified sampling on the binary outcome to preserve class prevalence.\n",
      "Stratified samplinghere means that we performed the splitwithin each\n",
      "outcome class(class 1 and class 0) and then combined the selected patients,\n",
      "\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "preserving training. Also, include other surgery specific and patient\n",
      "psychological factors, other outcomes of relevance for decision making.\n",
      "2.Learning under imbalance:integrate calibrated re-weighting, adopt\n",
      "techniques like SMOTE/ADASYN/mixup, and generative augmenta-\n",
      "tion with clinical plausibility checks; evaluate minority-aware metrics\n",
      "prospectively.\n",
      "3.Temporal/external validation:perform temporal splits, external\n",
      "site validation, and pre-registered prospective studies; assess domain\n",
      "shift and transportability.\n",
      "4.Better targets and calibration:model continuous and time-to-\n",
      "eventendpoints; reportBrierscore/ECE;applytemperature/Plattcali-\n",
      "bration; usedecision-curveanalysistoquantifynetbenefitacrossthresh-\n",
      "olds.\n",
      "5.Uncertainty and reliability:add Bayesian/post-hoc uncertainty\n",
      "quantification, conformal prediction, and reject-option policies to flag\n",
      "cases for multidisciplinary review.\n",
      "6.Individualized treatment benefit:move beyond outcome predic-\n",
      "tion to estimate conditional treatment effects (uplift models, causal\n",
      "\n",
      "Figure 3: Ensemble decision-support pipeline. Structured EHR data are cleaned and\n",
      "encoded, then passed in parallel to multiple base learners (Random Forest,Logistic\n",
      "Regression,SVM,MLPetc.). Their predictions are aggregated via a voting scheme to\n",
      "produce a binary surgery recommendation (Yes/No). Only preoperative variables are\n",
      "used for inference.\n",
      "6. Dataset Preparation\n",
      "6.1. Cleaning and Encoding\n",
      "Dataset cleaning is an important step for every machine learning model.\n",
      "This is of particular relevance for clinical data, as there are often challenges\n",
      "in the systematic measurement and recording of data that result from var-\n",
      "ied human factors. A messy dataset might negatively impact the prediction\n",
      "model, so it is necessary to examine and understand any flaws and address\n",
      "them wherever possible before training a model alongside reporting this pro-\n",
      "cess transparently. Here, this was accomplished in two parts. First, the data\n",
      "were cleaned and then preprocessed (encoding, then categorical to numerical\n",
      "conversion) to obtain a set of features suitable for ML training. Note, this\n",
      "process was repeated for both the 2R01 and 3R01 datasets.\n",
      "\n",
      "demographics, diagnoses, medications, laboratory values, and standardized\n",
      "patient-reported outcomes) and unstructured elements (e.g., free-text clini-\n",
      "cal notes), each offering complementary signals whose utility depends on the\n",
      "study context and modeling objective. In this work, we focus on structured\n",
      "preoperative clinical variables and standardized patient-reported outcomes,\n",
      "which are readily comparable across patients and amenable to reproducible\n",
      "model development. For treatment recommendations, risk stratification, and\n",
      "outcome forecasting in personalized medicine, ML models can help shoulder\n",
      "this cognitive load by learning patterns from large datasets and producing\n",
      "fast, reproducible risk estimates or recommendations [2]. In one possible\n",
      "collaborative paradigm, AI augments, not replaces, clinical judgment: physi-\n",
      "cians and patients focus their limited time on interpreting model-informed\n",
      "options, clarifying trade-offs, and engaging in shared decision-making. Al-\n",
      "though AI has transformed several diagnostic domains (e.g., imaging and\n",
      "digital pathology) [7], the next sequential phase of use in the treatment do-\n",
      "main remains comparatively underexplored.\n",
      "\n",
      "reported outcomes, including (1) a sinus-specific evaluation (SNOT-22), and\n",
      "(2) a general health measure (SF6d-derived health utility value, HUV) [39].\n",
      "A standardized collection of‚àº30 clinical and demographic common data ele-\n",
      "ments available to practicing physicians was performed throughout this study\n",
      "and used as the set of predictor variables.\n",
      "We began with a development cohort of 791 patients (50 attributes; typ-\n",
      "ical missingness for some clinical fields, referred to as the 2R01 dataset for\n",
      "the rest of the paper) and a second, independent cohort of 355 patients\n",
      "from a related multicenter CRS outcomes study with comparable clinician-\n",
      "recorded metadata (henceforth, referred to as the 3R01 dataset). In this\n",
      "paper, we restrict analysis to patients who actually underwent sinus surgery,\n",
      "because our objective is to build a model that flags cases that may be rec-\n",
      "ommended to avoid surgery (i.e., would not achieve sufficient postoperative\n",
      "benefit). Operationally, this means we considered only the ‚Äúsurgery‚Äù cases,\n",
      "excluded patients managed medically (no surgery). So, we concatenated the\n",
      "two cohorts, and retained only those with sinus surgery as the treatment. Af-\n",
      "\n",
      "LLM baselines are warranted. Finally, external generalizability remains to\n",
      "be proven; site effects, referral patterns, surgical technique and perioperative\n",
      "care, medication adherence, patient psychology, priming effects for survey\n",
      "responses are all considerations that may shift feature distributions.\n",
      "Clinical relevance.Even with these constraints,‚âà85%accuracy with trans-\n",
      "parent explanations is meaningful for preoperative counseling. Errors are not\n",
      "equivalent clinically: false negatives (predicting non-benefit when benefit is\n",
      "likely) may delay effective surgery, while false positives may expose a pa-\n",
      "tient to operative risk with limited expected gain. Our framework supports\n",
      "threshold tuning and individualized decision curves, enabling clinicians to\n",
      "select operating points aligned with patient preferences and risk tolerance.\n",
      "The interactive visualizations help communicate why the recommendation\n",
      "was made and how it might change under alternative assumptions.\n",
      "Future directions.We outline several priorities to translate these findings:\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "\n",
      "early detection accuracy and reduces diagnostic time.\n",
      "Methodology: Medical datasets are collected and preprocessed. Machine learning algorithms are\n",
      "trained on the data to identify disease-related patterns. Model performance is evaluated using\n",
      "accuracy and recall metrics.\n",
      "Results: The AI model demonstrated improved diagnostic accuracy and faster analysis compared\n",
      "to traditional methods.\n",
      "Conclusion: AI-based early detection systems can support healthcare professionals by improving\n",
      "speed and accuracy of diagnosis. These systems act as decision-support tools rather than\n",
      "replacements for doctors.\n",
      "\n",
      "Using Artificial Intelligence to Improve Early\n",
      "Disease Detection\n",
      "Abstract: Early detection of diseases such as cancer and diabetes significantly improves patient\n",
      "survival rates. Traditional diagnostic systems often rely on manual analysis, which can be slow and\n",
      "prone to human error. This research explores how Artificial Intelligence (AI) can assist in early\n",
      "disease detection using machine learning models.\n",
      "Introduction: Healthcare systems generate large volumes of medical data daily. Analyzing this data\n",
      "manually is challenging and time-consuming. AI systems can process complex datasets efficiently\n",
      "and identify patterns that may not be visible to human experts.\n",
      "Problem Statement: Many diseases are detected at later stages due to slow diagnostic procedures,\n",
      "human error, and limited access to medical specialists. Late diagnosis increases treatment costs\n",
      "and reduces survival probability.\n",
      "Objective: The objective of this research is to develop an AI-based predictive system that improves\n",
      "early detection accuracy and reduces diagnostic time.\n",
      "Methodology: Medical datasets are collected and preprocessed. Machine learning algorithms are\n",
      "\n",
      "demographics, diagnoses, medications, laboratory values, and standardized\n",
      "patient-reported outcomes) and unstructured elements (e.g., free-text clini-\n",
      "cal notes), each offering complementary signals whose utility depends on the\n",
      "study context and modeling objective. In this work, we focus on structured\n",
      "preoperative clinical variables and standardized patient-reported outcomes,\n",
      "which are readily comparable across patients and amenable to reproducible\n",
      "model development. For treatment recommendations, risk stratification, and\n",
      "outcome forecasting in personalized medicine, ML models can help shoulder\n",
      "this cognitive load by learning patterns from large datasets and producing\n",
      "fast, reproducible risk estimates or recommendations [2]. In one possible\n",
      "collaborative paradigm, AI augments, not replaces, clinical judgment: physi-\n",
      "cians and patients focus their limited time on interpreting model-informed\n",
      "options, clarifying trade-offs, and engaging in shared decision-making. Al-\n",
      "though AI has transformed several diagnostic domains (e.g., imaging and\n",
      "digital pathology) [7], the next sequential phase of use in the treatment do-\n",
      "main remains comparatively underexplored.\n",
      "\n",
      "dynamic areas of research and development worldwide. The foundational\n",
      "ideas date to the 1950s, when the Turing test was proposed as an opera-\n",
      "tional benchmark for machine intelligence. Subsequent methodological and\n",
      "hardware advances over the years have enabled translational applications\n",
      "across health sciences [1]. Today, AI and machine learning (ML) power\n",
      "a broad spectrum of products and services: from business analytics and\n",
      "robotics to voice-interactive assistants such as Siri, Alexa, and Google Assis-\n",
      "tant [2]. Healthcare, in particular, has seen rapid growth in AI investment\n",
      "and adoption since 2016, reflecting the potential of technology in this indus-\n",
      "try to improve outcomes and reduce costs [1, 3, 4, 5, 6].\n",
      "There are many uses for ML/AI in medical applications for clinical cases\n",
      "beyond basic operations. For clinicians, high-quality treatment recommenda-\n",
      "tions depend on deep domain expertise and experience in interpreting com-\n",
      "plex heterogeneous information. As electronic health records (EHRs) have\n",
      "become the primary medium of documentation, clinicians spend substan-\n",
      "tial time on data entry, yet the resulting information, collected in part to\n",
      "\n",
      "though AI has transformed several diagnostic domains (e.g., imaging and\n",
      "digital pathology) [7], the next sequential phase of use in the treatment do-\n",
      "main remains comparatively underexplored.\n",
      "Introducing AI-based data analytics to inform treatment selection enables\n",
      "physicians to synthesize data and findings learned from large, heterogeneous\n",
      "clinical datasets rapidly at the point-of-care. Objective, data-driven mod-\n",
      "eling can strengthen patient trust, help avoid unnecessary procedures, and\n",
      "support high-value, cost-effective care [8, 9, 10]. Neither AI nor the most\n",
      "experienced clinician can achieve100%accuracy; however, when used col-\n",
      "laboratively, ML predictions can complement human expertise and improve\n",
      "decision quality, standardizing subjective data interpretation, potentially el-\n",
      "evating less experienced non-specialty physicians [3, 11]. In this study, we\n",
      "report the results of supervised ML modeling in one of the most prevalent and\n",
      "costly health problems in the United States, Chronic Rhinosinusitis (CRS),\n",
      "which affects a substantial fraction of adults and is a leading driver of outpa-\n",
      "tient visits, medication use, and overall healthcare utilization [12, 13]. When\n",
      "\n",
      "at the individual level motivates our study: if clinicians and patients could\n",
      "accesspre-operative, patient-specific estimates of surgical benefit, they could\n",
      "better weigh procedural and anesthesia risks against likely QoL gains, engage\n",
      "in more informed shared decision-making, and set realistic expectations [11].\n",
      "Such individualized risk-benefit estimation is a central promise of personal-\n",
      "ized medicine and a key motivation for the rapid growth of structured data\n",
      "collection in healthcare over the past decade. Leveraging current AI/ML\n",
      "6\n",
      "\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "preserving training. Also, include other surgery specific and patient\n",
      "psychological factors, other outcomes of relevance for decision making.\n",
      "2.Learning under imbalance:integrate calibrated re-weighting, adopt\n",
      "techniques like SMOTE/ADASYN/mixup, and generative augmenta-\n",
      "tion with clinical plausibility checks; evaluate minority-aware metrics\n",
      "prospectively.\n",
      "3.Temporal/external validation:perform temporal splits, external\n",
      "site validation, and pre-registered prospective studies; assess domain\n",
      "shift and transportability.\n",
      "4.Better targets and calibration:model continuous and time-to-\n",
      "eventendpoints; reportBrierscore/ECE;applytemperature/Plattcali-\n",
      "bration; usedecision-curveanalysistoquantifynetbenefitacrossthresh-\n",
      "olds.\n",
      "5.Uncertainty and reliability:add Bayesian/post-hoc uncertainty\n",
      "quantification, conformal prediction, and reject-option policies to flag\n",
      "cases for multidisciplinary review.\n",
      "6.Individualized treatment benefit:move beyond outcome predic-\n",
      "tion to estimate conditional treatment effects (uplift models, causal\n",
      "\n",
      "3.4. Gap addressed in this work\n",
      "In sum, while guidelines endorse PRO-driven management and meta-\n",
      "analyses demonstrate average post-ESS improvements, there remains a clear\n",
      "gap: a systematic ML application toroutinely accessibleCRS clinical data\n",
      "that (i) frames the task as a pre-operative recommendation problem anchored\n",
      "to the SNOT-22 minimal clinically important difference, (ii) compares multi-\n",
      "ple algorithms and ensembles, (iii) prioritizes interpretability and visualiza-\n",
      "tion, and (iv) quantifies potential clinical utility compared to experts. Our\n",
      "study addresses these needs by building and evaluating such models on a\n",
      "8\n",
      "\n",
      "Figure 2: Schematic pipeline of the proposed decision-support approach. Structured fields\n",
      "from the electronic health record (EHR) undergo data cleaning and encoding, after which\n",
      "multiple in-house classifiers (e.g., MLP, logistic regression, SVM) are trained. Model\n",
      "outputs are combined via a majority-vote ensemble to generate a binary surgery recom-\n",
      "mendation (Yes/No).\n",
      "In this work, we framed CRS surgical selection as a supervised, pre-\n",
      "operative classification problem and compared multiple algorithms including\n",
      "regularized logistic regression, SVMs, random forests, gradient-boosted trees,\n",
      "Na√Øve Bayes, a compact three-layer DNN, and a majority-vote ensemble, us-\n",
      "ing stratified validation and a held-out test set. We report discrimination\n",
      "(e.g., AUROC), and error profiles (e.g., class-0 recall and macro-F1), consis-\n",
      "tent with best practices for clinical prediction modeling [37, 35, 11]. Regard-\n",
      "ing patient and public involvement, neither was involved in the study design\n",
      "or any feedback collection.\n",
      "5.2. Machine Learning Approaches Utilized\n",
      "We implement the binary classification models usingscikit-learn[44]\n",
      "andXGBoost[45] libraries. In Stage 1, we train and benchmark individual\n",
      "\n",
      "imbalance-aware learning, rigorous external validation, and careful calibra-\n",
      "tion will be key to translating such models from retrospective studies to\n",
      "prospective, decision-support tools that improve patient counseling and, ul-\n",
      "timately, outcomes.\n",
      "ACKNOWLEDGMENT\n",
      "This work was supported by a grant from the National Institute of Al-\n",
      "lergy and Infectious Diseases (NIAID) of the National Institutes of Health\n",
      "under grant number R01AI175631 (VRR). Contents are the authors‚Äô sole\n",
      "responsibility and do not necessarily represent official NIH views.\n",
      "Appendix A. Tripod AI Check\n",
      "I checked mostly, we may need to confirm 1 point: fairness.\n",
      "32\n",
      "\n",
      "Across surgery more broadly, interpretable ML is increasingly explored to\n",
      "augment case selection, perioperative risk stratification, and shared decision-\n",
      "making [11, 7, 3]. Also transparency in the process from data gathering,\n",
      "processing, assessment, experiments, reporting etc. is now expected, using\n",
      "TRIPOD+AI guidelines as we do here [33] or similar alternative (CHAI [34]).\n",
      "A paper in this arena should follow at least one of these and mention which\n",
      "one. Best practices emphasize calibration, transparency of feature influence,\n",
      "and evaluation of net clinical utility versus treat-all or treat-none heuristics\n",
      "[11]. However, translation to CRS has lagged: most published clinical ML\n",
      "algorithms either rely on imaging-heavy pipelines or small, single-center co-\n",
      "horts, and they frequently omit core translational checks such as probability\n",
      "calibration and decision-curve (net-benefit) analysis‚Äîsteps that are essential\n",
      "for clinical deployment [31, 11, 35, 36, 37, 38].\n",
      "3.4. Gap addressed in this work\n",
      "In sum, while guidelines endorse PRO-driven management and meta-\n",
      "analyses demonstrate average post-ESS improvements, there remains a clear\n",
      "\n",
      "demographics, diagnoses, medications, laboratory values, and standardized\n",
      "patient-reported outcomes) and unstructured elements (e.g., free-text clini-\n",
      "cal notes), each offering complementary signals whose utility depends on the\n",
      "study context and modeling objective. In this work, we focus on structured\n",
      "preoperative clinical variables and standardized patient-reported outcomes,\n",
      "which are readily comparable across patients and amenable to reproducible\n",
      "model development. For treatment recommendations, risk stratification, and\n",
      "outcome forecasting in personalized medicine, ML models can help shoulder\n",
      "this cognitive load by learning patterns from large datasets and producing\n",
      "fast, reproducible risk estimates or recommendations [2]. In one possible\n",
      "collaborative paradigm, AI augments, not replaces, clinical judgment: physi-\n",
      "cians and patients focus their limited time on interpreting model-informed\n",
      "options, clarifying trade-offs, and engaging in shared decision-making. Al-\n",
      "though AI has transformed several diagnostic domains (e.g., imaging and\n",
      "digital pathology) [7], the next sequential phase of use in the treatment do-\n",
      "main remains comparatively underexplored.\n",
      "\n",
      "Figure 3: Ensemble decision-support pipeline. Structured EHR data are cleaned and\n",
      "encoded, then passed in parallel to multiple base learners (Random Forest,Logistic\n",
      "Regression,SVM,MLPetc.). Their predictions are aggregated via a voting scheme to\n",
      "produce a binary surgery recommendation (Yes/No). Only preoperative variables are\n",
      "used for inference.\n",
      "6. Dataset Preparation\n",
      "6.1. Cleaning and Encoding\n",
      "Dataset cleaning is an important step for every machine learning model.\n",
      "This is of particular relevance for clinical data, as there are often challenges\n",
      "in the systematic measurement and recording of data that result from var-\n",
      "ied human factors. A messy dataset might negatively impact the prediction\n",
      "model, so it is necessary to examine and understand any flaws and address\n",
      "them wherever possible before training a model alongside reporting this pro-\n",
      "cess transparently. Here, this was accomplished in two parts. First, the data\n",
      "were cleaned and then preprocessed (encoding, then categorical to numerical\n",
      "conversion) to obtain a set of features suitable for ML training. Note, this\n",
      "process was repeated for both the 2R01 and 3R01 datasets.\n",
      "\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "preserving training. Also, include other surgery specific and patient\n",
      "psychological factors, other outcomes of relevance for decision making.\n",
      "2.Learning under imbalance:integrate calibrated re-weighting, adopt\n",
      "techniques like SMOTE/ADASYN/mixup, and generative augmenta-\n",
      "tion with clinical plausibility checks; evaluate minority-aware metrics\n",
      "prospectively.\n",
      "3.Temporal/external validation:perform temporal splits, external\n",
      "site validation, and pre-registered prospective studies; assess domain\n",
      "shift and transportability.\n",
      "4.Better targets and calibration:model continuous and time-to-\n",
      "eventendpoints; reportBrierscore/ECE;applytemperature/Plattcali-\n",
      "bration; usedecision-curveanalysistoquantifynetbenefitacrossthresh-\n",
      "olds.\n",
      "5.Uncertainty and reliability:add Bayesian/post-hoc uncertainty\n",
      "quantification, conformal prediction, and reject-option policies to flag\n",
      "cases for multidisciplinary review.\n",
      "6.Individualized treatment benefit:move beyond outcome predic-\n",
      "tion to estimate conditional treatment effects (uplift models, causal\n",
      "\n",
      "Across surgery more broadly, interpretable ML is increasingly explored to\n",
      "augment case selection, perioperative risk stratification, and shared decision-\n",
      "making [11, 7, 3]. Also transparency in the process from data gathering,\n",
      "processing, assessment, experiments, reporting etc. is now expected, using\n",
      "TRIPOD+AI guidelines as we do here [33] or similar alternative (CHAI [34]).\n",
      "A paper in this arena should follow at least one of these and mention which\n",
      "one. Best practices emphasize calibration, transparency of feature influence,\n",
      "and evaluation of net clinical utility versus treat-all or treat-none heuristics\n",
      "[11]. However, translation to CRS has lagged: most published clinical ML\n",
      "algorithms either rely on imaging-heavy pipelines or small, single-center co-\n",
      "horts, and they frequently omit core translational checks such as probability\n",
      "calibration and decision-curve (net-benefit) analysis‚Äîsteps that are essential\n",
      "for clinical deployment [31, 11, 35, 36, 37, 38].\n",
      "3.4. Gap addressed in this work\n",
      "In sum, while guidelines endorse PRO-driven management and meta-\n",
      "analyses demonstrate average post-ESS improvements, there remains a clear\n",
      "\n",
      "7.Human‚ÄìAI collaboration:expand reader studies, measure assis-\n",
      "tance effects (with/without model), and optimize the UI for rapid,\n",
      "explainable triage; incorporate clinician feedback loops for continual\n",
      "learning.\n",
      "8.Foundation/self-supervisedmodels:ourTabPFNexplorationshowed\n",
      "strong class 1 discrimination but limited minority recall; future work\n",
      "willtesttabularfoundationmodelsandhybridpipelines(self-supervised\n",
      "feature learning + calibrated discriminators) under imbalance con-\n",
      "straints.\n",
      "9. Conclusion\n",
      "We present an interpretable, data-efficient pipeline for predicting CRS\n",
      "surgical outcomes. An optimized MLP achieved strong discrimination on a\n",
      "held-out cohort and surpassed both a generative-AI baseline and expected\n",
      "human performance on a stratified reader set, while providing transparent\n",
      "global and local explanations. The principal limitation is minority-class per-\n",
      "formance driven by class imbalance and sample size, ubiquitous challenges\n",
      "in medical outcome prediction. Addressing these with targeted data growth,\n",
      "imbalance-aware learning, rigorous external validation, and careful calibra-\n",
      "tion will be key to translating such models from retrospective studies to\n",
      "\n",
      "demographics, diagnoses, medications, laboratory values, and standardized\n",
      "patient-reported outcomes) and unstructured elements (e.g., free-text clini-\n",
      "cal notes), each offering complementary signals whose utility depends on the\n",
      "study context and modeling objective. In this work, we focus on structured\n",
      "preoperative clinical variables and standardized patient-reported outcomes,\n",
      "which are readily comparable across patients and amenable to reproducible\n",
      "model development. For treatment recommendations, risk stratification, and\n",
      "outcome forecasting in personalized medicine, ML models can help shoulder\n",
      "this cognitive load by learning patterns from large datasets and producing\n",
      "fast, reproducible risk estimates or recommendations [2]. In one possible\n",
      "collaborative paradigm, AI augments, not replaces, clinical judgment: physi-\n",
      "cians and patients focus their limited time on interpreting model-informed\n",
      "options, clarifying trade-offs, and engaging in shared decision-making. Al-\n",
      "though AI has transformed several diagnostic domains (e.g., imaging and\n",
      "digital pathology) [7], the next sequential phase of use in the treatment do-\n",
      "main remains comparatively underexplored.\n",
      "\n",
      "early detection accuracy and reduces diagnostic time.\n",
      "Methodology: Medical datasets are collected and preprocessed. Machine learning algorithms are\n",
      "trained on the data to identify disease-related patterns. Model performance is evaluated using\n",
      "accuracy and recall metrics.\n",
      "Results: The AI model demonstrated improved diagnostic accuracy and faster analysis compared\n",
      "to traditional methods.\n",
      "Conclusion: AI-based early detection systems can support healthcare professionals by improving\n",
      "speed and accuracy of diagnosis. These systems act as decision-support tools rather than\n",
      "replacements for doctors.\n",
      "\n",
      "tiered summaries that facilitate both localized entity-specific inquiries and\n",
      "overarching community-level assessments.\n",
      "5.5.3 MedGraphRAG Domain-Specific Implementation\n",
      "MedGraphRAG implements a triple-tier architecture that links user docu-\n",
      "ments to medical textbooks and the UMLS knowledge store, demonstrating\n",
      "24\n",
      "\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "preserving training. Also, include other surgery specific and patient\n",
      "psychological factors, other outcomes of relevance for decision making.\n",
      "2.Learning under imbalance:integrate calibrated re-weighting, adopt\n",
      "techniques like SMOTE/ADASYN/mixup, and generative augmenta-\n",
      "tion with clinical plausibility checks; evaluate minority-aware metrics\n",
      "prospectively.\n",
      "3.Temporal/external validation:perform temporal splits, external\n",
      "site validation, and pre-registered prospective studies; assess domain\n",
      "shift and transportability.\n",
      "4.Better targets and calibration:model continuous and time-to-\n",
      "eventendpoints; reportBrierscore/ECE;applytemperature/Plattcali-\n",
      "bration; usedecision-curveanalysistoquantifynetbenefitacrossthresh-\n",
      "olds.\n",
      "5.Uncertainty and reliability:add Bayesian/post-hoc uncertainty\n",
      "quantification, conformal prediction, and reject-option policies to flag\n",
      "cases for multidisciplinary review.\n",
      "6.Individualized treatment benefit:move beyond outcome predic-\n",
      "tion to estimate conditional treatment effects (uplift models, causal\n",
      "\n",
      "become the primary medium of documentation, clinicians spend substan-\n",
      "tial time on data entry, yet the resulting information, collected in part to\n",
      "enable billing and administrative workflows and in part to support clinical\n",
      "care and longitudinal analysis, remains difficult to synthesize during brief pa-\n",
      "tient encounters. In addition, EHR data span both structured elements (e.g.,\n",
      "2\n",
      "\n",
      "Secondly, modularity facilitates plug-and-play compatibility among compo-\n",
      "nents, thereby enabling precise optimization and domain-specific customiza-\n",
      "tion across the retriever, reranker, and generator stages [8]. Enterprise de-\n",
      "ployments have shown that modular RAG architectures significantly reduce\n",
      "technology refresh expenses and facilitate the quicker integration of new\n",
      "features in comparison to monolithic methodologies [9].\n",
      "Third, citation traceability improves interpretability and credibility by as-\n",
      "sociating generated outputs with specific evidence passages, which is con-\n",
      "sistent with the increasing emphasis on accountability and explainability in\n",
      "AI systems [10][11]. In comparison to systems that lack attribution func-\n",
      "tionalities, enterprise implementations that integrate comprehensive citation\n",
      "frameworks report enhanced user trust ratings and decreased support esca-\n",
      "lations [12].\n",
      "In contexts where empirical accuracy, timeliness, and transparency are es-\n",
      "sential, such as legal analytics, biomedical inquiry resolution, and regulatory\n",
      "compliance tools, these advantages are especially apparent [13][14]. The sys-\n",
      "\n",
      "Pipeline\n",
      "Type Examples\n",
      "Coordination\n",
      "Approach\n",
      "Flexibility\n",
      "Level\n",
      "Static FiD [15], RAG [1] Rule-based\n",
      "workflows\n",
      "Limited\n",
      "Agentic AutoRAG [22],\n",
      "Self-RAG [24]\n",
      "Model-driven\n",
      "adaptation\n",
      "High\n",
      "4.6 Architectural Integration Patterns\n",
      "Modern RAG systems increasingly combine multiple taxonomic dimensions\n",
      "to address specific application requirements. The taxonomy enables sys-\n",
      "tematic analysis of architectural trade-offs across retrieval strategies, fusion\n",
      "mechanisms, modality support, trust calibration, and adaptivity levels.\n",
      "Integration patterns emerge where latency-critical applications employ\n",
      "single-pass retrieval with early fusion, while complex reasoning tasks utilize\n",
      "multi-hop retrieval with agentic coordination. Trust calibration mechanisms\n",
      "integrate across all architectural dimensions to ensure reliable operation.\n",
      "Table 4.4: Architectural Integration Patterns in RAG Systems\n",
      "Pattern\n",
      "Type Use Case\n",
      "Key Charac-\n",
      "teristics Strengths\n",
      "Trade-offs\n",
      "/\n",
      "Challenges\n",
      "Single-Pass\n",
      "Early\n",
      "Fusion\n",
      "Latency-\n",
      "sensitive\n",
      "applications\n",
      "(e.g.,\n",
      "real-time\n",
      "assistants)\n",
      "One-shot\n",
      "retrieval; early\n",
      "fusion; low\n",
      "coordination\n",
      "Low latency;\n",
      "simple\n",
      "architecture\n",
      "Limited\n",
      "depth;\n",
      "lower\n",
      "robustness\n",
      "Multi-Hop\n",
      "Late Fusion\n",
      "Complex\n",
      "reasoning\n",
      "\n",
      "to facilitate real-time entity retrieval, scalable domain-adaptive graph\n",
      "augmentation, and enhance evidence traceability.\n",
      "5.5.2 Microsoft GraphRAG Implementation\n",
      "The innovative approach of Microsoft GraphRAG generates knowledge\n",
      "graphs from unstructured text autonomously using large language models,\n",
      "constructing entity-relationship networks through community discovery\n",
      "techniques [21]. Robust industry adoption and endorsement of the graph-\n",
      "based methodology were demonstrated by the over 20,000 GitHub stars\n",
      "that the open-source release in July 2024 received. The publicly docu-\n",
      "mented GraphRAG specification and project notes provide implementation\n",
      "guidance and examples for production use [79]‚Äì[80], [83].\n",
      "The system utilizes a three-phase methodology: entity extraction by GPT-4\n",
      "with specialized prompts, relationship mapping through co-occurrence anal-\n",
      "ysis and semantic similarity, and community recognition with the Leiden\n",
      "algorithm for hierarchical clustering [71]. Every community produces multi-\n",
      "tiered summaries that facilitate both localized entity-specific inquiries and\n",
      "overarching community-level assessments.\n",
      "5.5.3 MedGraphRAG Domain-Specific Implementation\n",
      "\n",
      "assist users, and ensure medication adherence. With a focus  \n",
      "on improving healthcare accessibility and quality, the system \n",
      "integrated smart pill dispensers for monitoring and enhancing \n",
      "medication adherence , offering great potential in revolution - \n",
      "izing healthcare services. Ahamed explores the application \n",
      "of IoT and Machine Learning in Personalized Healthcare  \n",
      "(PH) to enhance disease management and intervention. IoT \n",
      "sensor devices and wearables collect patien t data, which is \n",
      "analyzed using AI and ML techniques for disease prediction \n",
      "and patient self -management. Challenges include biased data \n",
      "collection, outdated training datasets, and privacy concerns. \n",
      "The integration of IoT and ML in PH faces issues such as data \n",
      "transmission reliability and biased training datasets, impacting \n",
      "diagnostic accuracy. Addressing these challenges is crucial for \n",
      "improving personalized healthcare systems. Khurana imple - \n",
      "ments a Smart Healthcare System using IoT sensors to enhance \n",
      "patient care in hospitals. The system utilizes Ultrasonic and IR \n",
      "Proximity Sensors connected to an Arduino Uno for automated \n",
      "IV fluid level monitoring and patient alarm system. The liter -\n",
      "\n",
      "dynamic areas of research and development worldwide. The foundational\n",
      "ideas date to the 1950s, when the Turing test was proposed as an opera-\n",
      "tional benchmark for machine intelligence. Subsequent methodological and\n",
      "hardware advances over the years have enabled translational applications\n",
      "across health sciences [1]. Today, AI and machine learning (ML) power\n",
      "a broad spectrum of products and services: from business analytics and\n",
      "robotics to voice-interactive assistants such as Siri, Alexa, and Google Assis-\n",
      "tant [2]. Healthcare, in particular, has seen rapid growth in AI investment\n",
      "and adoption since 2016, reflecting the potential of technology in this indus-\n",
      "try to improve outcomes and reduce costs [1, 3, 4, 5, 6].\n",
      "There are many uses for ML/AI in medical applications for clinical cases\n",
      "beyond basic operations. For clinicians, high-quality treatment recommenda-\n",
      "tions depend on deep domain expertise and experience in interpreting com-\n",
      "plex heterogeneous information. As electronic health records (EHRs) have\n",
      "become the primary medium of documentation, clinicians spend substan-\n",
      "tial time on data entry, yet the resulting information, collected in part to\n",
      "\n",
      "demographics, diagnoses, medications, laboratory values, and standardized\n",
      "patient-reported outcomes) and unstructured elements (e.g., free-text clini-\n",
      "cal notes), each offering complementary signals whose utility depends on the\n",
      "study context and modeling objective. In this work, we focus on structured\n",
      "preoperative clinical variables and standardized patient-reported outcomes,\n",
      "which are readily comparable across patients and amenable to reproducible\n",
      "model development. For treatment recommendations, risk stratification, and\n",
      "outcome forecasting in personalized medicine, ML models can help shoulder\n",
      "this cognitive load by learning patterns from large datasets and producing\n",
      "fast, reproducible risk estimates or recommendations [2]. In one possible\n",
      "collaborative paradigm, AI augments, not replaces, clinical judgment: physi-\n",
      "cians and patients focus their limited time on interpreting model-informed\n",
      "options, clarifying trade-offs, and engaging in shared decision-making. Al-\n",
      "though AI has transformed several diagnostic domains (e.g., imaging and\n",
      "digital pathology) [7], the next sequential phase of use in the treatment do-\n",
      "main remains comparatively underexplored.\n",
      "\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "preserving training. Also, include other surgery specific and patient\n",
      "psychological factors, other outcomes of relevance for decision making.\n",
      "2.Learning under imbalance:integrate calibrated re-weighting, adopt\n",
      "techniques like SMOTE/ADASYN/mixup, and generative augmenta-\n",
      "tion with clinical plausibility checks; evaluate minority-aware metrics\n",
      "prospectively.\n",
      "3.Temporal/external validation:perform temporal splits, external\n",
      "site validation, and pre-registered prospective studies; assess domain\n",
      "shift and transportability.\n",
      "4.Better targets and calibration:model continuous and time-to-\n",
      "eventendpoints; reportBrierscore/ECE;applytemperature/Plattcali-\n",
      "bration; usedecision-curveanalysistoquantifynetbenefitacrossthresh-\n",
      "olds.\n",
      "5.Uncertainty and reliability:add Bayesian/post-hoc uncertainty\n",
      "quantification, conformal prediction, and reject-option policies to flag\n",
      "cases for multidisciplinary review.\n",
      "6.Individualized treatment benefit:move beyond outcome predic-\n",
      "tion to estimate conditional treatment effects (uplift models, causal\n",
      "\n",
      "at the individual level motivates our study: if clinicians and patients could\n",
      "accesspre-operative, patient-specific estimates of surgical benefit, they could\n",
      "better weigh procedural and anesthesia risks against likely QoL gains, engage\n",
      "in more informed shared decision-making, and set realistic expectations [11].\n",
      "Such individualized risk-benefit estimation is a central promise of personal-\n",
      "ized medicine and a key motivation for the rapid growth of structured data\n",
      "collection in healthcare over the past decade. Leveraging current AI/ML\n",
      "6\n",
      "\n",
      "early detection accuracy and reduces diagnostic time.\n",
      "Methodology: Medical datasets are collected and preprocessed. Machine learning algorithms are\n",
      "trained on the data to identify disease-related patterns. Model performance is evaluated using\n",
      "accuracy and recall metrics.\n",
      "Results: The AI model demonstrated improved diagnostic accuracy and faster analysis compared\n",
      "to traditional methods.\n",
      "Conclusion: AI-based early detection systems can support healthcare professionals by improving\n",
      "speed and accuracy of diagnosis. These systems act as decision-support tools rather than\n",
      "replacements for doctors.\n",
      "\n",
      "Across surgery more broadly, interpretable ML is increasingly explored to\n",
      "augment case selection, perioperative risk stratification, and shared decision-\n",
      "making [11, 7, 3]. Also transparency in the process from data gathering,\n",
      "processing, assessment, experiments, reporting etc. is now expected, using\n",
      "TRIPOD+AI guidelines as we do here [33] or similar alternative (CHAI [34]).\n",
      "A paper in this arena should follow at least one of these and mention which\n",
      "one. Best practices emphasize calibration, transparency of feature influence,\n",
      "and evaluation of net clinical utility versus treat-all or treat-none heuristics\n",
      "[11]. However, translation to CRS has lagged: most published clinical ML\n",
      "algorithms either rely on imaging-heavy pipelines or small, single-center co-\n",
      "horts, and they frequently omit core translational checks such as probability\n",
      "calibration and decision-curve (net-benefit) analysis‚Äîsteps that are essential\n",
      "for clinical deployment [31, 11, 35, 36, 37, 38].\n",
      "3.4. Gap addressed in this work\n",
      "In sum, while guidelines endorse PRO-driven management and meta-\n",
      "analyses demonstrate average post-ESS improvements, there remains a clear\n",
      "\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "preserving training. Also, include other surgery specific and patient\n",
      "psychological factors, other outcomes of relevance for decision making.\n",
      "2.Learning under imbalance:integrate calibrated re-weighting, adopt\n",
      "techniques like SMOTE/ADASYN/mixup, and generative augmenta-\n",
      "tion with clinical plausibility checks; evaluate minority-aware metrics\n",
      "prospectively.\n",
      "3.Temporal/external validation:perform temporal splits, external\n",
      "site validation, and pre-registered prospective studies; assess domain\n",
      "shift and transportability.\n",
      "4.Better targets and calibration:model continuous and time-to-\n",
      "eventendpoints; reportBrierscore/ECE;applytemperature/Plattcali-\n",
      "bration; usedecision-curveanalysistoquantifynetbenefitacrossthresh-\n",
      "olds.\n",
      "5.Uncertainty and reliability:add Bayesian/post-hoc uncertainty\n",
      "quantification, conformal prediction, and reject-option policies to flag\n",
      "cases for multidisciplinary review.\n",
      "6.Individualized treatment benefit:move beyond outcome predic-\n",
      "tion to estimate conditional treatment effects (uplift models, causal\n",
      "\n",
      "early detection accuracy and reduces diagnostic time.\n",
      "Methodology: Medical datasets are collected and preprocessed. Machine learning algorithms are\n",
      "trained on the data to identify disease-related patterns. Model performance is evaluated using\n",
      "accuracy and recall metrics.\n",
      "Results: The AI model demonstrated improved diagnostic accuracy and faster analysis compared\n",
      "to traditional methods.\n",
      "Conclusion: AI-based early detection systems can support healthcare professionals by improving\n",
      "speed and accuracy of diagnosis. These systems act as decision-support tools rather than\n",
      "replacements for doctors.\n",
      "\n",
      "3.4. Gap addressed in this work\n",
      "In sum, while guidelines endorse PRO-driven management and meta-\n",
      "analyses demonstrate average post-ESS improvements, there remains a clear\n",
      "gap: a systematic ML application toroutinely accessibleCRS clinical data\n",
      "that (i) frames the task as a pre-operative recommendation problem anchored\n",
      "to the SNOT-22 minimal clinically important difference, (ii) compares multi-\n",
      "ple algorithms and ensembles, (iii) prioritizes interpretability and visualiza-\n",
      "tion, and (iv) quantifies potential clinical utility compared to experts. Our\n",
      "study addresses these needs by building and evaluating such models on a\n",
      "8\n",
      "\n",
      "Using Artificial Intelligence to Improve Early\n",
      "Disease Detection\n",
      "Abstract: Early detection of diseases such as cancer and diabetes significantly improves patient\n",
      "survival rates. Traditional diagnostic systems often rely on manual analysis, which can be slow and\n",
      "prone to human error. This research explores how Artificial Intelligence (AI) can assist in early\n",
      "disease detection using machine learning models.\n",
      "Introduction: Healthcare systems generate large volumes of medical data daily. Analyzing this data\n",
      "manually is challenging and time-consuming. AI systems can process complex datasets efficiently\n",
      "and identify patterns that may not be visible to human experts.\n",
      "Problem Statement: Many diseases are detected at later stages due to slow diagnostic procedures,\n",
      "human error, and limited access to medical specialists. Late diagnosis increases treatment costs\n",
      "and reduces survival probability.\n",
      "Objective: The objective of this research is to develop an AI-based predictive system that improves\n",
      "early detection accuracy and reduces diagnostic time.\n",
      "Methodology: Medical datasets are collected and preprocessed. Machine learning algorithms are\n",
      "\n",
      "LLM baselines are warranted. Finally, external generalizability remains to\n",
      "be proven; site effects, referral patterns, surgical technique and perioperative\n",
      "care, medication adherence, patient psychology, priming effects for survey\n",
      "responses are all considerations that may shift feature distributions.\n",
      "Clinical relevance.Even with these constraints,‚âà85%accuracy with trans-\n",
      "parent explanations is meaningful for preoperative counseling. Errors are not\n",
      "equivalent clinically: false negatives (predicting non-benefit when benefit is\n",
      "likely) may delay effective surgery, while false positives may expose a pa-\n",
      "tient to operative risk with limited expected gain. Our framework supports\n",
      "threshold tuning and individualized decision curves, enabling clinicians to\n",
      "select operating points aligned with patient preferences and risk tolerance.\n",
      "The interactive visualizations help communicate why the recommendation\n",
      "was made and how it might change under alternative assumptions.\n",
      "Future directions.We outline several priorities to translate these findings:\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "preserving training. Also, include other surgery specific and patient\n",
      "psychological factors, other outcomes of relevance for decision making.\n",
      "2.Learning under imbalance:integrate calibrated re-weighting, adopt\n",
      "techniques like SMOTE/ADASYN/mixup, and generative augmenta-\n",
      "tion with clinical plausibility checks; evaluate minority-aware metrics\n",
      "prospectively.\n",
      "3.Temporal/external validation:perform temporal splits, external\n",
      "site validation, and pre-registered prospective studies; assess domain\n",
      "shift and transportability.\n",
      "4.Better targets and calibration:model continuous and time-to-\n",
      "eventendpoints; reportBrierscore/ECE;applytemperature/Plattcali-\n",
      "bration; usedecision-curveanalysistoquantifynetbenefitacrossthresh-\n",
      "olds.\n",
      "5.Uncertainty and reliability:add Bayesian/post-hoc uncertainty\n",
      "quantification, conformal prediction, and reject-option policies to flag\n",
      "cases for multidisciplinary review.\n",
      "6.Individualized treatment benefit:move beyond outcome predic-\n",
      "tion to estimate conditional treatment effects (uplift models, causal\n",
      "\n",
      "LLM baselines are warranted. Finally, external generalizability remains to\n",
      "be proven; site effects, referral patterns, surgical technique and perioperative\n",
      "care, medication adherence, patient psychology, priming effects for survey\n",
      "responses are all considerations that may shift feature distributions.\n",
      "Clinical relevance.Even with these constraints,‚âà85%accuracy with trans-\n",
      "parent explanations is meaningful for preoperative counseling. Errors are not\n",
      "equivalent clinically: false negatives (predicting non-benefit when benefit is\n",
      "likely) may delay effective surgery, while false positives may expose a pa-\n",
      "tient to operative risk with limited expected gain. Our framework supports\n",
      "threshold tuning and individualized decision curves, enabling clinicians to\n",
      "select operating points aligned with patient preferences and risk tolerance.\n",
      "The interactive visualizations help communicate why the recommendation\n",
      "was made and how it might change under alternative assumptions.\n",
      "Future directions.We outline several priorities to translate these findings:\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "\n",
      "Available:https://www.firecrawl.dev/blog/best-enterprise-rag-p\n",
      "latforms-2025\n",
      "[227] ‚ÄúOpen Source LLMs Have Higher ROI for Enterprise GenAI,‚Äù Prolego,\n",
      "2024. [Online]. Available:https://prolego.com/open-source-llms-hav\n",
      "e-higher-roi-for-enterprise-genai\n",
      "[228] ‚Äú10 Enterprise AI Stats to Know in 2024,‚Äù Skim AI, 2024. [Online].\n",
      "Available:https://skimai.com/10-enterprise-ai-stats-to-know-i\n",
      "n-2024/\n",
      "[229] ‚ÄúEnterprise AI Implementation Framework,‚Äù AIRC Conference, 2024.\n",
      "[Online]. Available:https://aircconline.com/csit/papers/vol15/cs\n",
      "it150301.pdf\n",
      "[230] ‚ÄúDifferentiable Data Rewards for RAG,‚Äù arXiv:2503.08398, 2025. [On-\n",
      "line]. Available:https://arxiv.org/html/2503.08398v1\n",
      "[231] ‚ÄúCollective Constitutional AI: Aligning a Language Model with Public\n",
      "Input,‚Äù Anthropic, 2023. [Online]. Available:https://www.anthropic.co\n",
      "m/research/collective-constitutional-ai-aligning-a-language-m\n",
      "odel-with-public-input\n",
      "85\n",
      "\n",
      "utilize their existing knowledge assets while simultaneously adhering to data\n",
      "governance and compliance regulations [229].\n",
      "10.3 Comparative Analysis and Future Research Directions\n",
      "Research Areas of High Priority (1-2 Years): The most optimistic near-\n",
      "term advancement is end-to-end optimization, which has shown substantial\n",
      "improvements over traditional two-stage approaches, such as Differentiable\n",
      "Data Rewards (DDR) [230]. Constitutional AI integration provides supe-\n",
      "rior safety and alignment in comparison to conventional RLHF methods,\n",
      "thereby facilitating more dependable and trustworthy RAG implementa-\n",
      "tions [222][223][231]. Standardized evaluation frameworks are indispensable\n",
      "for the systematic comparison and enhancement of performance, with ini-\n",
      "tiatives such as RAGChecker offering precise diagnostic capabilities [209].\n",
      "Developments of Medium Priority (2-5 years): In comparison to single-agent\n",
      "architectures, multi-agent RAG systems exhibit superior performance, par-\n",
      "ticularly for complex, multi-source information integration tasks [211][212].\n",
      "Research has shown that collaborative multi-agent approaches can enhance\n",
      "\n",
      "urces/blog/ai-and-data/how-to-secure-rag-applications-AI\n",
      "[156] ‚ÄúImplement human-in-the-loop confirmation with Amazon Bedrock\n",
      "Agents,‚Äù AWS Machine Learning Blog, Apr. 9, 2025. [Online]. Available:\n",
      "https://aws.amazon.com/blogs/machine-learning/implement-human\n",
      "-in-the-loop-confirmation-with-amazon-bedrock-agents/\n",
      "[157] H. Zhou et al., ‚ÄúTrustRAG: Enhancing Robustness and Trustworthi-\n",
      "ness in RAG,‚Äù arXiv preprint arXiv:2501.00879, 2025. [Online]. Available:\n",
      "https://arxiv.org/html/2501.00879v1\n",
      "[158] ‚ÄúTrustRAG: The RAG Framework within Reliable input, Trusted out-\n",
      "put,‚Äù GitHub, Feb. 4, 2024. [Online]. Available:https://github.com/g\n",
      "omate-community/TrustRAG\n",
      "[159] B. Zhang et al., ‚ÄúBenchmarking Poisoning Attacks against Retrieval-\n",
      "Augmented Generation,‚Äù arXiv preprint arXiv:2505.18543, 2025. [Online].\n",
      "Available:https://arxiv.org/abs/2505.18543\n",
      "[160] ‚ÄúLLM Red Teaming: The Complete Step-By-Step Guide To LLM\n",
      "Safety,‚Äù Confident AI, May 18, 2025. [Online]. Available:https://ww\n",
      "w.confident-ai.com/blog/red-teaming-llms-a-step-by-step-guide\n",
      "[161] ‚ÄúRed Teaming for Large Language Models: A Comprehensive Guide,‚Äù\n",
      "79\n",
      "\n",
      "ng44/navigating-trust-in-retrieval-augmented-ai-a-comprehensi\n",
      "ve-survey-4pif\n",
      "[146] J. Wei et al., ‚ÄúAlignRAG: An Adaptable Framework for Re-\n",
      "solving Misalignments in Retrieval-Aware Reasoning of RAG,‚Äù arXiv\n",
      "preprint arXiv:2504.14858, 2024. [Online]. Available:h t t p s :\n",
      "//arxiv.org/html/2504.14858v1\n",
      "[147] J. Su et al., ‚ÄúTowards More Robust Retrieval-Augmented Genera-\n",
      "tion: EvaluatingRAGUnderAdversarialPoisoningAttacks,‚Äù arXivpreprint\n",
      "arXiv:2412.16708, 2024. [Online]. Available:https://arxiv.org/abs/24\n",
      "12.16708\n",
      "[148] ‚ÄúEnhancing AI Security in Production: Key Insights on LLMs &\n",
      "RAG,‚Äù J2 Interactive, 2024. [Online]. Available:https://www.j2inte\n",
      "ractive.com/blog/2024/07/global-summit-ai-security/\n",
      "[149] ‚ÄúA Proactive Approach to RAG Application Security,‚Äù Akira AI, Mar.\n",
      "11, 2025. [Online]. Available:https://www.akira.ai/blog/rag-applica\n",
      "tion-security\n",
      "78\n",
      "\n",
      "tee dependable operation at scale, production implementations necessitate\n",
      "meticulous attention to caching strategies, failsafe mechanisms, and latency\n",
      "management [228].\n",
      "For Business Stakeholders: RAG systems generate quantifiable business\n",
      "value by means of numerous channels, such as accelerated enrollment, re-\n",
      "duced model maintenance costs, reduced time-to-insight, and improved risk\n",
      "management [219]. The technology allows organizations to more effectively\n",
      "62\n",
      "\n",
      "optimization in production environments is provided by enterprise-grade\n",
      "evaluation platforms [101]. These platforms typically provide real-time mon-\n",
      "itoring capabilities, automated evaluation pipelines, and integration with\n",
      "existing development workflows [110]. Vendor documentation details refer-\n",
      "ence integrations for monitoring, evaluation, and governance in enterprise\n",
      "RAG [91]‚Äì[92].\n",
      "Table 7.7: Enterprise RAG Evaluation Platforms\n",
      "Platform\n",
      "Automation\n",
      "Level\n",
      "Real-time\n",
      "Monitoring\n",
      "Custom\n",
      "Metrics\n",
      "Integration\n",
      "Capability\n",
      "Deployment\n",
      "Options\n",
      "Galileo\n",
      "AI\n",
      "Very\n",
      "High\n",
      "Yes Yes Extensive Cloud/On-\n",
      "premise\n",
      "LangSmith High Yes Yes Good Cloud\n",
      "34\n",
      "\n",
      "outputs\n",
      "Near\n",
      "real-time\n",
      "High Moderate\n",
      "Sampling\n",
      "Review\n",
      "Statistical\n",
      "sampling\n",
      "Periodic Moderate High\n",
      "Expert\n",
      "Validation\n",
      "Critical\n",
      "decisions only\n",
      "Variable Highest Limited\n",
      "Feedback\n",
      "Loop\n",
      "Iterative\n",
      "improvement\n",
      "Ongoing Progressive High\n",
      "48\n",
      "\n",
      "Using Artificial Intelligence to Improve Early\n",
      "Disease Detection\n",
      "Abstract: Early detection of diseases such as cancer and diabetes significantly improves patient\n",
      "survival rates. Traditional diagnostic systems often rely on manual analysis, which can be slow and\n",
      "prone to human error. This research explores how Artificial Intelligence (AI) can assist in early\n",
      "disease detection using machine learning models.\n",
      "Introduction: Healthcare systems generate large volumes of medical data daily. Analyzing this data\n",
      "manually is challenging and time-consuming. AI systems can process complex datasets efficiently\n",
      "and identify patterns that may not be visible to human experts.\n",
      "Problem Statement: Many diseases are detected at later stages due to slow diagnostic procedures,\n",
      "human error, and limited access to medical specialists. Late diagnosis increases treatment costs\n",
      "and reduces survival probability.\n",
      "Objective: The objective of this research is to develop an AI-based predictive system that improves\n",
      "early detection accuracy and reduces diagnostic time.\n",
      "Methodology: Medical datasets are collected and preprocessed. Machine learning algorithms are\n",
      "\n",
      "early detection accuracy and reduces diagnostic time.\n",
      "Methodology: Medical datasets are collected and preprocessed. Machine learning algorithms are\n",
      "trained on the data to identify disease-related patterns. Model performance is evaluated using\n",
      "accuracy and recall metrics.\n",
      "Results: The AI model demonstrated improved diagnostic accuracy and faster analysis compared\n",
      "to traditional methods.\n",
      "Conclusion: AI-based early detection systems can support healthcare professionals by improving\n",
      "speed and accuracy of diagnosis. These systems act as decision-support tools rather than\n",
      "replacements for doctors.\n",
      "\n",
      "Practice\n",
      "Category Recommendation\n",
      "Implementation\n",
      "Priority\n",
      "Impact\n",
      "Level\n",
      "Resource\n",
      "Require-\n",
      "ment\n",
      "Automated\n",
      "Pipeline\n",
      "Implement continuous\n",
      "evaluation workflows\n",
      "High High High\n",
      "Human-in-\n",
      "the-loop\n",
      "Integrate expert\n",
      "validation for critical\n",
      "applications\n",
      "Critical Very\n",
      "High\n",
      "Very High\n",
      "Domain-\n",
      "specific\n",
      "Metrics\n",
      "Develop specialized\n",
      "evaluation criteria\n",
      "Medium Medium Medium\n",
      "Real-time\n",
      "Monitoring\n",
      "Deploy production\n",
      "evaluation systems\n",
      "High High High\n",
      "Benchmark\n",
      "Standardiza-\n",
      "tion\n",
      "Adopt\n",
      "industry-standard\n",
      "datasets\n",
      "Medium Medium Low\n",
      "The evaluation of RAGs must be effective by balancing the quality of the\n",
      "assessment with the efficiency of automation. This can be achieved by uti-\n",
      "lizing both traditional metrics for baseline performance and advanced LLM-\n",
      "based judges for semantic evaluation [103]. To guarantee consistent system\n",
      "performance across a variety of deployment scenarios, organizations should\n",
      "establish exhaustive evaluation frameworks that facilitate both real-time\n",
      "production monitoring and offline development optimization [110][111].\n",
      "7 Engineering Patterns and Anti-Patterns\n",
      "Through extensive production deployments in a variety of enterprise envi-\n",
      "\n",
      "Using Artificial Intelligence to Improve Early\n",
      "Disease Detection\n",
      "Abstract: Early detection of diseases such as cancer and diabetes significantly improves patient\n",
      "survival rates. Traditional diagnostic systems often rely on manual analysis, which can be slow and\n",
      "prone to human error. This research explores how Artificial Intelligence (AI) can assist in early\n",
      "disease detection using machine learning models.\n",
      "Introduction: Healthcare systems generate large volumes of medical data daily. Analyzing this data\n",
      "manually is challenging and time-consuming. AI systems can process complex datasets efficiently\n",
      "and identify patterns that may not be visible to human experts.\n",
      "Problem Statement: Many diseases are detected at later stages due to slow diagnostic procedures,\n",
      "human error, and limited access to medical specialists. Late diagnosis increases treatment costs\n",
      "and reduces survival probability.\n",
      "Objective: The objective of this research is to develop an AI-based predictive system that improves\n",
      "early detection accuracy and reduces diagnostic time.\n",
      "Methodology: Medical datasets are collected and preprocessed. Machine learning algorithms are\n",
      "\n",
      "demographics, diagnoses, medications, laboratory values, and standardized\n",
      "patient-reported outcomes) and unstructured elements (e.g., free-text clini-\n",
      "cal notes), each offering complementary signals whose utility depends on the\n",
      "study context and modeling objective. In this work, we focus on structured\n",
      "preoperative clinical variables and standardized patient-reported outcomes,\n",
      "which are readily comparable across patients and amenable to reproducible\n",
      "model development. For treatment recommendations, risk stratification, and\n",
      "outcome forecasting in personalized medicine, ML models can help shoulder\n",
      "this cognitive load by learning patterns from large datasets and producing\n",
      "fast, reproducible risk estimates or recommendations [2]. In one possible\n",
      "collaborative paradigm, AI augments, not replaces, clinical judgment: physi-\n",
      "cians and patients focus their limited time on interpreting model-informed\n",
      "options, clarifying trade-offs, and engaging in shared decision-making. Al-\n",
      "though AI has transformed several diagnostic domains (e.g., imaging and\n",
      "digital pathology) [7], the next sequential phase of use in the treatment do-\n",
      "main remains comparatively underexplored.\n",
      "\n",
      "cases for multidisciplinary review.\n",
      "6.Individualized treatment benefit:move beyond outcome predic-\n",
      "tion to estimate conditional treatment effects (uplift models, causal\n",
      "forests) to quantify patient-specific expected gain from surgery versus\n",
      "medical therapy.\n",
      "31\n",
      "\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "preserving training. Also, include other surgery specific and patient\n",
      "psychological factors, other outcomes of relevance for decision making.\n",
      "2.Learning under imbalance:integrate calibrated re-weighting, adopt\n",
      "techniques like SMOTE/ADASYN/mixup, and generative augmenta-\n",
      "tion with clinical plausibility checks; evaluate minority-aware metrics\n",
      "prospectively.\n",
      "3.Temporal/external validation:perform temporal splits, external\n",
      "site validation, and pre-registered prospective studies; assess domain\n",
      "shift and transportability.\n",
      "4.Better targets and calibration:model continuous and time-to-\n",
      "eventendpoints; reportBrierscore/ECE;applytemperature/Plattcali-\n",
      "bration; usedecision-curveanalysistoquantifynetbenefitacrossthresh-\n",
      "olds.\n",
      "5.Uncertainty and reliability:add Bayesian/post-hoc uncertainty\n",
      "quantification, conformal prediction, and reject-option policies to flag\n",
      "cases for multidisciplinary review.\n",
      "6.Individualized treatment benefit:move beyond outcome predic-\n",
      "tion to estimate conditional treatment effects (uplift models, causal\n",
      "\n",
      "LLM baselines are warranted. Finally, external generalizability remains to\n",
      "be proven; site effects, referral patterns, surgical technique and perioperative\n",
      "care, medication adherence, patient psychology, priming effects for survey\n",
      "responses are all considerations that may shift feature distributions.\n",
      "Clinical relevance.Even with these constraints,‚âà85%accuracy with trans-\n",
      "parent explanations is meaningful for preoperative counseling. Errors are not\n",
      "equivalent clinically: false negatives (predicting non-benefit when benefit is\n",
      "likely) may delay effective surgery, while false positives may expose a pa-\n",
      "tient to operative risk with limited expected gain. Our framework supports\n",
      "threshold tuning and individualized decision curves, enabling clinicians to\n",
      "select operating points aligned with patient preferences and risk tolerance.\n",
      "The interactive visualizations help communicate why the recommendation\n",
      "was made and how it might change under alternative assumptions.\n",
      "Future directions.We outline several priorities to translate these findings:\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "\n",
      "ments in SNOT-22, yet with wide interpatient variability [14, 15]. Current\n",
      "guidelines provide indication frameworks, but they stop short of offering in-\n",
      "dividualized, pre-operative predictions of benefit using routinely available\n",
      "clinical variables [30]. This creates a practical gap for clinicians and patients\n",
      "seeking personalized risk‚Äìbenefit estimates to guide shared decision-making.\n",
      "3.2. Predictive models in rhinology and sinus surgery\n",
      "Predictive modeling in rhinology remains comparatively sparse and het-\n",
      "erogeneous. Prioreffortsincluderegression-basedandmachine-learning(ML)\n",
      "approachesthatassociatebaselinesymptomburdenandselectedclinicalvari-\n",
      "ables with post-operative SNOT-22 trajectories or satisfaction; for example,\n",
      "Kanget al.used SNOT-22 to model outcomes after septoplasty [31], while\n",
      "largemeta-analysesquantifiedaveragegainsbutwerenotdesignedasindivid-\n",
      "ualized risk calculators [14, 15, 29]. Much of the existing literature centers on\n",
      "population-level effect sizes, disease control categories, or biomarker/imaging\n",
      "correlates rather than point-of-care prediction from routine pre-operative\n",
      "clinical records [13]. Consequently, there is no widely adopted, validated\n",
      "\n",
      "Attack\n",
      "Category\n",
      "Simulation\n",
      "Method\n",
      "Detection\n",
      "Challenge\n",
      "Business\n",
      "Impact\n",
      "Countermeasure\n",
      "Priority\n",
      "Data\n",
      "Poisoning\n",
      "Malicious\n",
      "content\n",
      "injection\n",
      "High Critical Maximum\n",
      "Prompt\n",
      "Injection\n",
      "Query\n",
      "manipulation\n",
      "testing\n",
      "Medium High High\n",
      "Social\n",
      "Engineering\n",
      "Human factor\n",
      "exploitation\n",
      "Variable High High\n",
      "Technical\n",
      "Exploitation\n",
      "System\n",
      "vulnerability\n",
      "testing\n",
      "Low Medium Medium\n",
      "Bias\n",
      "Exploitation\n",
      "Systematic\n",
      "preference\n",
      "testing\n",
      "High High High\n",
      "8.5 Regulatory Compliance and Governance Frameworks\n",
      "In order to guarantee legal compliance, mitigate risk, and maintain ethical\n",
      "standards, comprehensive governance frameworks are required for the im-\n",
      "plementation of RAG systems in regulated industries. [164][165]. The NIST\n",
      "AI Risk Management Framework underscores the importance of fostering a\n",
      "risk-aware organizational culture [166][167].\n",
      "Industry-Specific Compliance Requirements\n",
      "The implementation of RAG systems presents distinct regulatory challenges\n",
      "for various sectors [168].\n",
      "Table 9.9: Regulatory Compliance Framework by Sector\n",
      "Sector\n",
      "Primary\n",
      "Regulations\n",
      "Key\n",
      "Requirements\n",
      "Compliance\n",
      "Mechanisms\n",
      "Enforcement\n",
      "Level\n",
      "Healthcare HIPAA, FDA,\n",
      "WHO Guidelines\n",
      "Privacy\n",
      "protection, safety\n",
      "validation\n",
      "Audit trails,\n",
      "encryption\n",
      "Strict\n",
      "\n",
      "Industry-Specific Risk Assessment\n",
      "Industries are subject to varying degrees of RAG-related hazards, which are\n",
      "determined by their regulatory obligations and data sensitivity [154].\n",
      "Table 9.4: Industry Risk Profile Comparison\n",
      "Industry\n",
      "Primary Risk\n",
      "Categories\n",
      "Regulatory\n",
      "Framework\n",
      "Audit Re-\n",
      "quirements\n",
      "Risk\n",
      "Toler-\n",
      "ance\n",
      "Healthcare Privacy violations,\n",
      "bias in diagnoses\n",
      "HIPAA,\n",
      "FDA\n",
      "Continuous Very\n",
      "Low\n",
      "Financial\n",
      "Services\n",
      "Market manipulation,\n",
      "algorithmic bias\n",
      "SEC,\n",
      "FINRA\n",
      "Quarterly Low\n",
      "Legal Citation fraud,\n",
      "precedent\n",
      "misrepresentation\n",
      "Professional\n",
      "codes\n",
      "Ongoing Very\n",
      "Low\n",
      "GovernmentInformation warfare,\n",
      "decision manipulation\n",
      "Security\n",
      "standards\n",
      "Continuous Minimal\n",
      "Education Misinformation,\n",
      "academic bias\n",
      "FERPA,\n",
      "COPPA\n",
      "Annual Medium\n",
      "8.3 Comprehensive Mitigation Strategies\n",
      "Deliberate, multifaceted mitigation strategies that address vulnerabilities\n",
      "throughout the entire information lifecycle are necessary to establish reli-\n",
      "able RAG systems [155]. In addition to safeguarding consumers, organi-\n",
      "zations are also protected from legal and reputational risks by adhering to\n",
      "frameworks such as GDPR, CCPA, and SOC 2 [155].\n",
      "Technical Defense Mechanisms\n",
      "\n",
      "Impact\n",
      "Chain-of-\n",
      "Thought\n",
      "Step-by-step\n",
      "reasoning\n",
      "prompts\n",
      "Low Moderate Minimal\n",
      "Counterfactual\n",
      "Filtering\n",
      "Cross-\n",
      "demographic\n",
      "validation\n",
      "Medium High Low\n",
      "Adversarial\n",
      "Prompting\n",
      "Identity-aware\n",
      "prompt design\n",
      "Medium Moderate Low\n",
      "Majority\n",
      "Vote\n",
      "Aggregation\n",
      "Multi-variant\n",
      "output\n",
      "combination\n",
      "High Highest Medium\n",
      "Demographic\n",
      "Parity\n",
      "Balanced\n",
      "representation\n",
      "enforcement\n",
      "High High Medium\n",
      "This comprehensive approach to RAG trust, alignment, and safety equips\n",
      "organizations with the frameworks and tools required to deploy compliant,\n",
      "52\n",
      "\n",
      "Sector\n",
      "Primary\n",
      "Regulations\n",
      "Key\n",
      "Requirements\n",
      "Compliance\n",
      "Mechanisms\n",
      "Enforcement\n",
      "Level\n",
      "Healthcare HIPAA, FDA,\n",
      "WHO Guidelines\n",
      "Privacy\n",
      "protection, safety\n",
      "validation\n",
      "Audit trails,\n",
      "encryption\n",
      "Strict\n",
      "Financial SEC, FINRA,\n",
      "Basel III\n",
      "Algorithmic\n",
      "transparency, fair\n",
      "lending\n",
      "Real-time\n",
      "monitoring\n",
      "Strict\n",
      "50\n",
      "\n",
      "1.Data growth and harmonization:expand to broader cohorts; stan-\n",
      "dardize variable definitions; leverage federated learning for privacy-\n",
      "preserving training. Also, include other surgery specific and patient\n",
      "psychological factors, other outcomes of relevance for decision making.\n",
      "2.Learning under imbalance:integrate calibrated re-weighting, adopt\n",
      "techniques like SMOTE/ADASYN/mixup, and generative augmenta-\n",
      "tion with clinical plausibility checks; evaluate minority-aware metrics\n",
      "prospectively.\n",
      "3.Temporal/external validation:perform temporal splits, external\n",
      "site validation, and pre-registered prospective studies; assess domain\n",
      "shift and transportability.\n",
      "4.Better targets and calibration:model continuous and time-to-\n",
      "eventendpoints; reportBrierscore/ECE;applytemperature/Plattcali-\n",
      "bration; usedecision-curveanalysistoquantifynetbenefitacrossthresh-\n",
      "olds.\n",
      "5.Uncertainty and reliability:add Bayesian/post-hoc uncertainty\n",
      "quantification, conformal prediction, and reject-option policies to flag\n",
      "cases for multidisciplinary review.\n",
      "6.Individualized treatment benefit:move beyond outcome predic-\n",
      "tion to estimate conditional treatment effects (uplift models, causal\n",
      "\n",
      "utilize their existing knowledge assets while simultaneously adhering to data\n",
      "governance and compliance regulations [229].\n",
      "10.3 Comparative Analysis and Future Research Directions\n",
      "Research Areas of High Priority (1-2 Years): The most optimistic near-\n",
      "term advancement is end-to-end optimization, which has shown substantial\n",
      "improvements over traditional two-stage approaches, such as Differentiable\n",
      "Data Rewards (DDR) [230]. Constitutional AI integration provides supe-\n",
      "rior safety and alignment in comparison to conventional RLHF methods,\n",
      "thereby facilitating more dependable and trustworthy RAG implementa-\n",
      "tions [222][223][231]. Standardized evaluation frameworks are indispensable\n",
      "for the systematic comparison and enhancement of performance, with ini-\n",
      "tiatives such as RAGChecker offering precise diagnostic capabilities [209].\n",
      "Developments of Medium Priority (2-5 years): In comparison to single-agent\n",
      "architectures, multi-agent RAG systems exhibit superior performance, par-\n",
      "ticularly for complex, multi-source information integration tasks [211][212].\n",
      "Research has shown that collaborative multi-agent approaches can enhance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'researcher': {'answer': 'Achievable.\\n\\nWhy this is feasible based on the provided context:\\n- Data modalities and modeling approach exist\\n  - The context demonstrates building AI/ML models from structured EHR data augmented with patient-reported outcomes, with data cleaning, encoding, and normalization steps, and evaluation using accuracy, recall, AUROC, and calibration metrics.\\n  - Time-to-diagnosis can be framed as a time-to-event endpoint and modeled with approaches mentioned (better targets and calibration, time-to-event modeling, decision-curve/net-benefit analysis).\\n  - Multimodal data (EMR, imaging, labs) are acknowledged as targets; the framework supports integrating heterogeneous signals via ensemble/triangulated modeling and parallel learners.\\n- Large-scale, multi-institution data handling is addressed\\n  - The context explicitly discusses data growth, harmonization, and standard definitions, with federated learning for privacy-preserving training, and external/temporal validation to assess transportability.\\n  - Anonymization and privacy-preserving analytics are foregrounded, aligning with assembling multi-institution datasets that capture time-to-diagnosis, misdiagnoses, and outcomes.\\n- Interoperability and governance are contemplated\\n  - Although not detailing every standard, the text emphasizes data interoperability considerations (standard ontologies, privacy, governance, and HIPAA-like/regulatory framing) and the importance of net clinical utility and calibration, which map to the ethical/equity/regulatory subtasks.\\n- Clinician-facing decision support and workflow standardization are supported\\n  - The described AI/ML predictive pipelines are designed as decision-support rather than replacements for clinicians, with ensemble voting to produce actionable recommendations and with explanations/interpretability emphasized.\\n  - The inclusion of uncertainty quantification, transparency, and decision curves supports reducing cognitive bias and standardizing workflows.\\n- Roadmap elements align with the subtasks\\n  - Build a scalable data analysis pipeline, implement privacy-preserving analytics, prototype clinician decision-support tools, develop risk stratification, and evaluate regulatory/ethical/equity implications are all coherently suggested by the context.\\n  - Concepts for real-time monitoring, dashboards, and rapid insight generation are compatible with ‚Äúreal-time dashboards and alert systems‚Äù and enterprise RAG-style evaluation patterns mentioned in the material.\\n\\nGaps and considerations to address for full realization\\n- Disease breadth vs. dataset scope\\n  - The context provides concrete examples (e.g., CRS surgery prediction) rather than a universal demonstration across multiple late-detection diseases. Extending to broad late-disease detection may require integrating more diverse disease domains and tailored feature sets.\\n- Imaging and lab data integration specifics\\n  - While imaging and lab data are acknowledged as targets, the context primarily details structured EHR/PRO-based modeling. Implementing robust imaging/Lab pipelines would require additional modeling approaches (e.g., image-based ML) and data pipelines beyond the explicit examples given.\\n- Interoperability standards detail\\n  - The plan references FHIR/HL7 in the subtasks but the context does not provide concrete implementations or results for interoperability; practical deployment would need concrete integration with these standards.\\n- Validation and generalizability\\n  - External validation and cross-site generalizability are highlighted as priorities, but explicit results or demonstrated success across diverse institutions and patient populations are not provided in the context. This would need prospective, multi-site validation studies.\\n- Ethical/regulatory/ equity specifics\\n  - While governance and risk frameworks are discussed, actionable, disease-wide equity assessments and regulatory approvals would need to be planned and reported in practice.\\n\\nBottom line\\n- Based on the described methodology (large-scale, multi-institution, privacy-preserving, calibrated, interpretable AI with time-to-event framing and clinician-facing decision support) the goal of improving early detection for late-diagnosis diseases via AI-assisted screening/triage, standardized workflows, and scalable analytics is feasible within this framework. The main work remaining is broadening disease coverage, operationalizing full multimodal data integration (including imaging/labs), implementing concrete interoperability with standards like FHIR/HL7, and conducting prospective, multi-institution validation to demonstrate real-world effectiveness and equity.',\n",
       "  'sources': [{'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "    'page': 0},\n",
       "   {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "    'page': 0},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 1},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2411.18583v1.pdf', 'page': 4},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "    'page': 0},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2411.18583v1.pdf', 'page': 1},\n",
       "   {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "    'page': 0},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2411.18583v1.pdf', 'page': 1},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2411.18583v1.pdf', 'page': 1},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2411.18583v1.pdf', 'page': 5},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2510.22344v1.pdf', 'page': 18},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2510.22344v1.pdf', 'page': 29},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2510.25621v1.pdf', 'page': 18},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2510.22344v1.pdf', 'page': 18},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 37},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2510.22344v1.pdf', 'page': 17},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 17},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 14},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 2},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 8},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "    'page': 0},\n",
       "   {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "    'page': 0},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 2},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 1},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 2},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 5},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 7},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 10},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 31},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 7},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 2},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 14},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 7},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 31},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 2},\n",
       "   {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "    'page': 0},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 23},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 1},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 2},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 17},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 23},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2411.18583v1.pdf', 'page': 4},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 1},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 2},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 5},\n",
       "   {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "    'page': 0},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 7},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "    'page': 0},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 7},\n",
       "   {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "    'page': 0},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 84},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 62},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 78},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 77},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 61},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 33},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 47},\n",
       "   {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "    'page': 0},\n",
       "   {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "    'page': 0},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 35},\n",
       "   {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "    'page': 0},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 2},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 6},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 49},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 46},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 51},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 49},\n",
       "   {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "   {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 62}],\n",
       "  'next_agent': 'Evaluator'},\n",
       " 'final_answer': 'Achievable.\\n\\nWhy this is feasible based on the provided context:\\n- Data modalities and modeling approach exist\\n  - The context demonstrates building AI/ML models from structured EHR data augmented with patient-reported outcomes, with data cleaning, encoding, and normalization steps, and evaluation using accuracy, recall, AUROC, and calibration metrics.\\n  - Time-to-diagnosis can be framed as a time-to-event endpoint and modeled with approaches mentioned (better targets and calibration, time-to-event modeling, decision-curve/net-benefit analysis).\\n  - Multimodal data (EMR, imaging, labs) are acknowledged as targets; the framework supports integrating heterogeneous signals via ensemble/triangulated modeling and parallel learners.\\n- Large-scale, multi-institution data handling is addressed\\n  - The context explicitly discusses data growth, harmonization, and standard definitions, with federated learning for privacy-preserving training, and external/temporal validation to assess transportability.\\n  - Anonymization and privacy-preserving analytics are foregrounded, aligning with assembling multi-institution datasets that capture time-to-diagnosis, misdiagnoses, and outcomes.\\n- Interoperability and governance are contemplated\\n  - Although not detailing every standard, the text emphasizes data interoperability considerations (standard ontologies, privacy, governance, and HIPAA-like/regulatory framing) and the importance of net clinical utility and calibration, which map to the ethical/equity/regulatory subtasks.\\n- Clinician-facing decision support and workflow standardization are supported\\n  - The described AI/ML predictive pipelines are designed as decision-support rather than replacements for clinicians, with ensemble voting to produce actionable recommendations and with explanations/interpretability emphasized.\\n  - The inclusion of uncertainty quantification, transparency, and decision curves supports reducing cognitive bias and standardizing workflows.\\n- Roadmap elements align with the subtasks\\n  - Build a scalable data analysis pipeline, implement privacy-preserving analytics, prototype clinician decision-support tools, develop risk stratification, and evaluate regulatory/ethical/equity implications are all coherently suggested by the context.\\n  - Concepts for real-time monitoring, dashboards, and rapid insight generation are compatible with ‚Äúreal-time dashboards and alert systems‚Äù and enterprise RAG-style evaluation patterns mentioned in the material.\\n\\nGaps and considerations to address for full realization\\n- Disease breadth vs. dataset scope\\n  - The context provides concrete examples (e.g., CRS surgery prediction) rather than a universal demonstration across multiple late-detection diseases. Extending to broad late-disease detection may require integrating more diverse disease domains and tailored feature sets.\\n- Imaging and lab data integration specifics\\n  - While imaging and lab data are acknowledged as targets, the context primarily details structured EHR/PRO-based modeling. Implementing robust imaging/Lab pipelines would require additional modeling approaches (e.g., image-based ML) and data pipelines beyond the explicit examples given.\\n- Interoperability standards detail\\n  - The plan references FHIR/HL7 in the subtasks but the context does not provide concrete implementations or results for interoperability; practical deployment would need concrete integration with these standards.\\n- Validation and generalizability\\n  - External validation and cross-site generalizability are highlighted as priorities, but explicit results or demonstrated success across diverse institutions and patient populations are not provided in the context. This would need prospective, multi-site validation studies.\\n- Ethical/regulatory/ equity specifics\\n  - While governance and risk frameworks are discussed, actionable, disease-wide equity assessments and regulatory approvals would need to be planned and reported in practice.\\n\\nBottom line\\n- Based on the described methodology (large-scale, multi-institution, privacy-preserving, calibrated, interpretable AI with time-to-event framing and clinician-facing decision support) the goal of improving early detection for late-diagnosis diseases via AI-assisted screening/triage, standardized workflows, and scalable analytics is feasible within this framework. The main work remaining is broadening disease coverage, operationalizing full multimodal data integration (including imaging/labs), implementing concrete interoperability with standards like FHIR/HL7, and conducting prospective, multi-institution validation to demonstrate real-world effectiveness and equity.',\n",
       " 'final_sources': [{'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "   'page': 0},\n",
       "  {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "   'page': 0},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 1},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2411.18583v1.pdf', 'page': 4},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "   'page': 0},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2411.18583v1.pdf', 'page': 1},\n",
       "  {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "   'page': 0},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2411.18583v1.pdf', 'page': 1},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2411.18583v1.pdf', 'page': 1},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2411.18583v1.pdf', 'page': 5},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2510.22344v1.pdf', 'page': 18},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2510.22344v1.pdf', 'page': 29},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2510.25621v1.pdf', 'page': 18},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2510.22344v1.pdf', 'page': 18},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 37},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2510.22344v1.pdf', 'page': 17},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 17},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 14},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 2},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 8},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "   'page': 0},\n",
       "  {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "   'page': 0},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 2},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 1},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 2},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 5},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 7},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 10},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 31},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 7},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 2},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 14},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 7},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 31},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 2},\n",
       "  {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "   'page': 0},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 23},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 1},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 2},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 17},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 23},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2411.18583v1.pdf', 'page': 4},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 1},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 2},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 5},\n",
       "  {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "   'page': 0},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 7},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "   'page': 0},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 7},\n",
       "  {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "   'page': 0},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 84},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 62},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 78},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 77},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 61},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 33},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 47},\n",
       "  {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "   'page': 0},\n",
       "  {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "   'page': 0},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 35},\n",
       "  {'source': 'agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf',\n",
       "   'page': 0},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 2},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 6},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 49},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 46},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 51},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 49},\n",
       "  {'source': 'agent_workspace/papers_local/2602.17888v1.pdf', 'page': 30},\n",
       "  {'source': 'agent_workspace/papers_arxiv/2601.05264v1.pdf', 'page': 62}],\n",
       " 'next_agent': 'Evaluator'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researcher_agent(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a354826",
   "metadata": {},
   "source": [
    "## 6. Agent 3 ‚Äî Evaluator (Critic + Analyzer)\n",
    "\n",
    "- Judges whether the answer is sufficient  \n",
    "- Scores confidence (0‚Äì1)  \n",
    "- Detects missing aspects  \n",
    "- **Online mode:** routes to `END` if confidence ‚â• 0.75 **and** ‚â• 4 sources, else `Expansion`  \n",
    "- **Workspace mode:** routes to `END` once the vector DB has been exhausted (no new chunks possible), accepting a lower confidence threshold (‚â• 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72bab78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Evaluator prompt template ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "_evaluator_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are the Evaluator Agent.\n",
    "\n",
    "Research goal: {goal}\n",
    "Operating mode: {mode}\n",
    "\n",
    "Evaluate the following answer against the goal:\n",
    "<context>\n",
    "Answer: {answer}\n",
    "Number of sources: {num_sources}\n",
    "</context>\n",
    "\n",
    "Tasks:\n",
    "1. Score confidence from 0.0 to 1.0 (how well the answer covers the goal).\n",
    "2. List specific missing aspects (if any).\n",
    "3. Routing rule ‚Äî {mode_instruction}\n",
    "\n",
    "Return ONLY valid JSON (no markdown, no explanation):\n",
    "{{\"confidence\": 0.62, \"missing_aspects\": [\"...\", \"...\"], \"next_agent\": \"Expansion\"}}\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def evaluator_agent(state: AgentState) -> dict:\n",
    "    goal        = state[\"goal\"]\n",
    "    researcher   = state.get(\"researcher\", {}) if isinstance(state.get(\"researcher\", {}), dict) else {}\n",
    "    answer       = researcher.get(\"answer\", state.get(\"final_answer\", \"\"))\n",
    "    sources      = researcher.get(\"sources\", state.get(\"final_sources\", []))\n",
    "    mode         = state.get(\"search_mode\", \"workspace\")\n",
    "    print(f\"  üß™ [Evaluator] Mode={mode} | Judging answer ({len(sources)} sources)...\")\n",
    "\n",
    "    fallback = {\n",
    "        \"confidence\": 0.55 if len(sources) >= 3 else 0.30,\n",
    "        \"missing_aspects\": [\"experimental validation\", \"ablation studies\"],\n",
    "        \"next_agent\": \"Expansion\",\n",
    "    }\n",
    "\n",
    "    mode_instruction = (\n",
    "        \"Set next_agent to END only if answer quality is strong and coverage is high. \"\n",
    "        \"If the answer is incomplete, vague, or weakly evidenced, set next_agent to Expansion.\"\n",
    "        if mode == \"online\"\n",
    "        else\n",
    "        \"Workspace-only mode: be moderately lenient, but still avoid END if answer is vague/off-topic/unsupported. \"\n",
    "        \"Set next_agent to Expansion when quality is poor so ideas can still be generated.\"\n",
    "    )\n",
    "\n",
    "    # ‚îÄ‚îÄ LCEL evaluation chain: prompt | llm ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    # Mirrors the document_chain pattern from 1.1.2-Simpleapp\n",
    "    out = fallback\n",
    "    if llm is not None:\n",
    "        try:\n",
    "            eval_chain = _evaluator_prompt | llm\n",
    "            result = eval_chain.invoke({\n",
    "                \"goal\":             goal,\n",
    "                \"mode\":             mode,\n",
    "                \"answer\":           answer[:1500],\n",
    "                \"num_sources\":      len(sources),\n",
    "                \"mode_instruction\": mode_instruction,\n",
    "            })\n",
    "            raw = result.content.strip() if hasattr(result, \"content\") else str(result).strip()\n",
    "            # Strip markdown fences if present\n",
    "            if raw.startswith(\"```\"):\n",
    "                raw = raw.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            parsed = json.loads(raw)\n",
    "            out = parsed\n",
    "        except Exception as e:\n",
    "            print(f\"  üß™ [Evaluator] LLM chain error: {e}\")\n",
    "\n",
    "    confidence      = float(out.get(\"confidence\", fallback[\"confidence\"]))\n",
    "    missing_aspects = out.get(\"missing_aspects\", fallback[\"missing_aspects\"])\n",
    "    if not isinstance(missing_aspects, list):\n",
    "        missing_aspects = fallback[\"missing_aspects\"]\n",
    "\n",
    "    # ‚îÄ‚îÄ Deterministic quality checks (prevent false \"goal achieved\" routing) ‚îÄ‚îÄ\n",
    "    answer_clean   = answer.strip()\n",
    "    answer_len_ok  = len(answer_clean) >= 220\n",
    "    unique_sources = len({s.get(\"source\", \"\") for s in sources if isinstance(s, dict)})\n",
    "\n",
    "    stopwords = {\n",
    "        \"what\", \"which\", \"with\", \"from\", \"into\", \"that\", \"this\", \"those\", \"these\",\n",
    "        \"their\", \"there\", \"about\", \"have\", \"been\", \"being\", \"were\", \"when\", \"where\",\n",
    "        \"how\", \"can\", \"for\", \"and\", \"the\", \"are\", \"key\", \"overcome\", \"using\", \"than\",\n",
    "    }\n",
    "    goal_terms = [\n",
    "        w for w in ''.join(ch.lower() if ch.isalnum() else ' ' for ch in goal).split()\n",
    "        if len(w) >= 5 and w not in stopwords\n",
    "    ]\n",
    "    if goal_terms:\n",
    "        matches      = sum(1 for t in goal_terms if t in answer_clean.lower())\n",
    "        goal_coverage = matches / len(goal_terms)\n",
    "    else:\n",
    "        goal_coverage = 0.0\n",
    "\n",
    "    # Cap overly optimistic model confidence if grounding is weak\n",
    "    if not answer_clean or len(sources) == 0:\n",
    "        confidence = min(confidence, 0.30)\n",
    "    elif goal_coverage < 0.25 or unique_sources < 1:\n",
    "        confidence = min(confidence, 0.55)\n",
    "    elif unique_sources < 2:\n",
    "        confidence = min(confidence, 0.70)\n",
    "\n",
    "    if mode == \"workspace\":\n",
    "        sufficient = (\n",
    "            answer_len_ok\n",
    "            and len(sources) >= 1\n",
    "            and goal_coverage >= 0.30\n",
    "            and confidence >= 0.45\n",
    "        )\n",
    "    else:\n",
    "        sufficient = (\n",
    "            answer_len_ok\n",
    "            and len(sources) >= 3\n",
    "            and unique_sources >= 2\n",
    "            and goal_coverage >= 0.40\n",
    "            and confidence >= 0.72\n",
    "        )\n",
    "\n",
    "    next_agent = \"END\" if sufficient else \"Expansion\"\n",
    "\n",
    "    print(\n",
    "        \"  üß™ [Evaluator] \"\n",
    "        f\"Confidence={confidence:.2f} | Coverage={goal_coverage:.2f} | \"\n",
    "        f\"UniqueSources={unique_sources} | Sufficient={sufficient} | Next={next_agent}\"\n",
    "    )\n",
    "    return {\n",
    "        \"evaluator\": {\n",
    "            \"confidence\":      confidence,\n",
    "            \"missing_aspects\": missing_aspects,\n",
    "            \"next_agent\":      next_agent,\n",
    "        },\n",
    "        \"next_agent\": next_agent,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee34db",
   "metadata": {},
   "source": [
    "## 7. Agent 4 ‚Äî Expansion (Explorer + Innovator)\n",
    "\n",
    "**Online mode (`search_mode = \"online\"`):**\n",
    "- Searches ArXiv for papers covering missing aspects  \n",
    "- Ingests new PDFs into the vector DB  \n",
    "- If new papers found ‚Üí loops back to `Researcher`  \n",
    "- If saturated (no new papers **or** max iterations reached) ‚Üí generates ideas ‚Üí `END`\n",
    "\n",
    "**Workspace-only mode (`search_mode = \"workspace\"`):**\n",
    "- Skips all internet access  \n",
    "- Goes straight to generating novel research ideas from missing aspects  \n",
    "- Always routes to `END` (no new retrieval is possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92245aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expansion_agent(state: AgentState) -> dict:\n",
    "    goal           = state[\"goal\"]\n",
    "    vdb            = state[\"vdb\"]\n",
    "    missing        = state.get(\"evaluator\", {}).get(\"missing_aspects\", [])\n",
    "    iterations     = int(state.get(\"iterations\", 0)) + 1\n",
    "    max_iterations = int(state.get(\"max_iterations\", 4))\n",
    "    mode           = state.get(\"search_mode\", \"online\")\n",
    "    # Was the last Researcher call a total blank?\n",
    "    prev_answer    = state.get(\"final_answer\", \"\")\n",
    "    prev_sources   = state.get(\"final_sources\", [])\n",
    "\n",
    "    print(f\"  üöÄ [Expansion] Mode={mode} | Iteration {iterations}/{max_iterations}\")\n",
    "    print(f\"  üöÄ [Expansion] Missing aspects: {missing}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ Shared: generate novel research ideas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    def _generate_ideas(reason: str) -> list[str]:\n",
    "        print(f\"  üöÄ [Expansion] Generating ideas ({reason})...\")\n",
    "        fallback_ideas = {\n",
    "            \"ideas\": [\n",
    "                \"Design targeted experiments to address missing aspects.\",\n",
    "                \"Create stronger benchmarks with edge-case coverage.\",\n",
    "                \"Run ablation studies to isolate causal contributors.\",\n",
    "                \"Apply iterative human-in-the-loop error analysis.\",\n",
    "                \"Explore cross-domain transfer to validate generalisability.\",\n",
    "            ]\n",
    "        }\n",
    "        prompt = f\"\"\"You are the Expansion Agent.\n",
    "Research goal: {goal}\n",
    "Missing aspects: {missing}\n",
    "Reason for idea generation: {reason}\n",
    "\n",
    "Generate 4-6 concrete, novel research ideas or future directions\n",
    "that could address the missing aspects.\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "{{\"ideas\": [\"idea 1\", \"idea 2\", \"...\"]}}\"\"\"\n",
    "        out = _llm_json(prompt, fallback_ideas)\n",
    "        raw = out.get(\"ideas\", fallback_ideas[\"ideas\"])\n",
    "        return [str(x) for x in raw] if isinstance(raw, list) else fallback_ideas[\"ideas\"]\n",
    "\n",
    "    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "    # WORKSPACE-ONLY MODE ‚Äî no internet, ideas only\n",
    "    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "    if mode == \"workspace\":\n",
    "        ideas = _generate_ideas(\"workspace-only mode ‚Äî no ArXiv access\")\n",
    "\n",
    "        # Detect true insufficiency: DB was empty when Researcher ran\n",
    "        truly_insufficient = (len(prev_sources) == 0 and prev_answer == \"\")\n",
    "        if truly_insufficient:\n",
    "            insuff_reason = (\n",
    "                \"Workspace mode is active but the vector DB contains no documents. \"\n",
    "                f\"Add PDFs to {PDF_DIR.resolve()} and re-run Section 10.\"\n",
    "            )\n",
    "            print(f\"  üöÄ [Expansion] ‚ö†Ô∏è  INSUFFICIENT DATA ‚Äî {insuff_reason}\")\n",
    "        else:\n",
    "            insuff_reason = \"\"\n",
    "\n",
    "        print(f\"  üöÄ [Expansion] [WORKSPACE] Generated {len(ideas)} ideas ‚Üí END\")\n",
    "        out_dict = {\n",
    "            \"iterations\": iterations,\n",
    "            \"expansion\": {\n",
    "                \"mode\":              \"workspace\",\n",
    "                \"query\":             None,\n",
    "                \"papers_downloaded\": 0,\n",
    "                \"chunks_added\":      0,\n",
    "                \"saturated\":         True,\n",
    "                \"ideas\":             ideas,\n",
    "                \"next_agent\":        \"END\",\n",
    "            },\n",
    "            \"future_ideas\": ideas,\n",
    "            \"next_agent\":   \"END\",\n",
    "        }\n",
    "        if truly_insufficient:\n",
    "            out_dict[\"insufficient_data\"]     = True\n",
    "            out_dict[\"insufficiency_reason\"]  = insuff_reason\n",
    "        return out_dict\n",
    "\n",
    "    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "    # ONLINE MODE ‚Äî ArXiv search + ingest\n",
    "    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "    query      = f\"{goal} {' '.join(missing[:3])}\"\n",
    "    downloaded = arxiv_expand(query, max_results=4)\n",
    "    added      = ingest_dirs(vdb, [ARXIV_DIR]) if downloaded else 0\n",
    "    print(f\"  üöÄ [Expansion] [ONLINE] Downloaded {len(downloaded)} papers | Indexed {added} chunks\")\n",
    "\n",
    "    saturated  = (added == 0) or (iterations >= max_iterations)\n",
    "    ideas      = _generate_ideas(\"ArXiv saturated\") if saturated else []\n",
    "    next_agent = \"END\" if saturated else \"Researcher\"\n",
    "\n",
    "    # Detect true insufficiency: saturated on iteration 1 with no prior answer\n",
    "    truly_insufficient = (\n",
    "        saturated\n",
    "        and iterations == 1\n",
    "        and len(downloaded) == 0\n",
    "        and len(prev_sources) == 0\n",
    "    )\n",
    "    if truly_insufficient:\n",
    "        insuff_reason = (\n",
    "            f\"ArXiv returned no papers for the query: '{query}'. \"\n",
    "            \"The topic may be too niche, phrased unusually, or ArXiv may be unreachable. \"\n",
    "            \"Try rephrasing the research goal, adding local PDFs, or checking your connection.\"\n",
    "        )\n",
    "        print(f\"  üöÄ [Expansion] ‚ö†Ô∏è  INSUFFICIENT DATA ‚Äî {insuff_reason}\")\n",
    "    else:\n",
    "        insuff_reason = \"\"\n",
    "\n",
    "    print(f\"  üöÄ [Expansion] [ONLINE] Saturated={saturated} | Next={next_agent}\")\n",
    "    out_dict = {\n",
    "        \"iterations\": iterations,\n",
    "        \"expansion\": {\n",
    "            \"mode\":              \"online\",\n",
    "            \"query\":             query,\n",
    "            \"papers_downloaded\": len(downloaded),\n",
    "            \"chunks_added\":      added,\n",
    "            \"saturated\":         saturated,\n",
    "            \"ideas\":             ideas,\n",
    "            \"next_agent\":        next_agent,\n",
    "        },\n",
    "        \"future_ideas\": ideas,\n",
    "        \"next_agent\":   next_agent,\n",
    "    }\n",
    "    if truly_insufficient:\n",
    "        out_dict[\"insufficient_data\"]    = True\n",
    "        out_dict[\"insufficiency_reason\"] = insuff_reason\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83165faf",
   "metadata": {},
   "source": [
    "## 8. Dynamic Registry & Executor\n",
    "\n",
    "**No hard-coded edges between agents.**  \n",
    "A single `agent_executor` node reads `state['current_agent']`,  \n",
    "looks up the function in `AGENT_REGISTRY`, and calls it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57432e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registry: ['Planner', 'Researcher', 'Evaluator', 'Expansion']\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Registry: name ‚Üí function ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "AGENT_REGISTRY: dict[str, Callable[[AgentState], dict]] = {\n",
    "    \"Planner\":    planner_agent,\n",
    "    \"Researcher\": researcher_agent,\n",
    "    \"Evaluator\":  evaluator_agent,\n",
    "    \"Expansion\":  expansion_agent,\n",
    "}\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ Single dynamic executor node ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def agent_executor(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    The ONLY node in the graph.\n",
    "    Reads current_agent from state, dispatches to the right function,\n",
    "    then updates state with the result.\n",
    "    \"\"\"\n",
    "    # Resolve agent functions at runtime to avoid stale references when cells are re-run out of order.\n",
    "    runtime_registry: dict[str, Callable[[AgentState], dict]] = {\n",
    "        \"Planner\": planner_agent,\n",
    "        \"Researcher\": researcher_agent,\n",
    "        \"Evaluator\": evaluator_agent,\n",
    "        \"Expansion\": expansion_agent,\n",
    "    }\n",
    "\n",
    "    current = state.get(\"current_agent\", \"Planner\")\n",
    "    fn      = runtime_registry.get(current)\n",
    "\n",
    "    if fn is None:\n",
    "        print(f\"  ‚ùå Unknown agent: {current}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"next_agent\":    \"END\",\n",
    "            \"current_agent\": \"END\",\n",
    "            \"trace\":         state.get(\"trace\", []) + [f\"{current} -> UNKNOWN -> END\"],\n",
    "        }\n",
    "\n",
    "    # Run the agent\n",
    "    update     = fn(state)\n",
    "    next_agent = update.get(\"next_agent\", \"END\")\n",
    "    trace      = state.get(\"trace\", []) + [f\"{current} ‚Üí {next_agent}\"]\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        **update,\n",
    "        \"current_agent\": next_agent,\n",
    "        \"trace\":         trace,\n",
    "    }\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ Conditional routing function ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def route(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    After every agent_executor call:\n",
    "      - next_agent == 'END'  ‚Üí stop the graph\n",
    "      - anything else        ‚Üí loop back to agent_executor\n",
    "    \"\"\"\n",
    "    return \"END\" if state.get(\"next_agent\", \"END\") == \"END\" else \"LOOP\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ Registry:\", list(AGENT_REGISTRY.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c66847d",
   "metadata": {},
   "source": [
    "## 9. Build the LangGraph\n",
    "\n",
    "```\n",
    "  START\n",
    "    ‚îÇ\n",
    "    ‚ñº\n",
    " agent_executor  ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ                           ‚îÇ\n",
    "  route(state)                  ‚îÇ\n",
    "   /      \\                     ‚îÇ\n",
    " END      LOOP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "Only **one node**, one **conditional edge** ‚Äî routing is 100% data-driven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fd844a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangGraph compiled\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_graph():\n",
    "    g = StateGraph(AgentState)\n",
    "\n",
    "    # Single executor node\n",
    "    g.add_node(\"agent_executor\", agent_executor)\n",
    "\n",
    "    # Entry point\n",
    "    g.set_entry_point(\"agent_executor\")\n",
    "\n",
    "    # Dynamic routing ‚Äî no hard-coded agent-to-agent edges\n",
    "    g.add_conditional_edges(\n",
    "        \"agent_executor\",\n",
    "        route,\n",
    "        {\n",
    "            \"LOOP\": \"agent_executor\",   # run next agent in same node\n",
    "            \"END\":  END,                # terminate graph\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return g.compile()\n",
    "\n",
    "\n",
    "graph = build_graph()\n",
    "print(\"‚úÖ LangGraph compiled\")\n",
    "\n",
    "# Optional: visualise the graph structure\n",
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    print(\"  (graph visualisation requires pygraphviz ‚Äî skipping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6579e5",
   "metadata": {},
   "source": [
    "## 10. Initialise Vector DB & Ingest Local Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5e86f04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vector DB...\n",
      "Found 11 PDF(s) for ingestion\n",
      "  loaded: 2602.17888v1.pdf (48 pages)\n",
      "  loaded: 2510.25621v1.pdf (37 pages)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  failed: 1411.4413v2.pdf: PdfStreamError: Stream has ended unexpectedly\n",
      "  loaded: 2601.05264v1.pdf (86 pages)\n",
      "  loaded: 2411.18583v1.pdf (6 pages)\n",
      "  loaded: 2504.13684v1.pdf (8 pages)\n",
      "  loaded: 2401.15391v1.pdf (14 pages)\n",
      "  loaded: 2503.16581v1.pdf (11 pages)\n",
      "  loaded: 2502.13957v2.pdf (25 pages)\n",
      "  loaded: 2309.02144v1.pdf (19 pages)\n",
      "  loaded: 2510.22344v1.pdf (30 pages)\n",
      "Indexed 892 chunk(s) from 284 page(s)\n",
      "Collection total chunks: 894\n",
      "‚úÖ Vector DB ready | 892 chunks indexed from existing PDFs\n",
      "   Drop additional PDFs into: /workspaces/research-hub/agent_workspace/papers_local\n"
     ]
    }
   ],
   "source": [
    "print(\"Building vector DB...\")\n",
    "vdb = build_vectordb()\n",
    "\n",
    "# Ingest any PDFs already in the workspace\n",
    "chunks = ingest_dirs(vdb, [PDF_DIR, ARXIV_DIR])\n",
    "print(f\"‚úÖ Vector DB ready | {chunks} chunks indexed from existing PDFs\")\n",
    "print(f\"   Drop additional PDFs into: {PDF_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef47fc4e",
   "metadata": {},
   "source": [
    "## 11. Run the Autonomous Agent System\n",
    "\n",
    "**Choose your mode then run the cell below.**\n",
    "\n",
    "| `SEARCH_MODE` | What happens |\n",
    "|---------------|-------------|\n",
    "| `\"online\"` | Planner ‚Üí Researcher (local RAG) ‚Üí Evaluator ‚Üí **Expansion downloads ArXiv papers** ‚Üí loops until confident ‚Üí ideas |\n",
    "| `\"workspace\"` | Planner ‚Üí Researcher (local RAG only) ‚Üí Evaluator ‚Üí **Expansion generates ideas from existing knowledge** ‚Üí END |\n",
    "\n",
    "> **Tip ‚Äî workspace mode:** Make sure you have PDFs in `./agent_workspace/papers_local/`  \n",
    "> and have run **Section 10** so they are indexed before starting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "540965d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "MODE  : üíæ WORKSPACE ‚Äî local PDFs only, no internet\n",
      "GOAL  : To accurately predict a protein‚Äôs three-dimensional (3D) structure directly from its amino acid sequence using artificial intelligence, eliminating the need for time-consuming and expensive experimental methods.\n",
      "=================================================================\n",
      "\n",
      "=================================================================\n",
      "RUN COMPLETE\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "# ‚ïë                    CONFIGURE HERE                           ‚ïë\n",
    "# ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "# ‚ïë  SEARCH_MODE                                                ‚ïë\n",
    "# ‚ïë    \"online\"    ‚Äî search ArXiv for missing papers            ‚ïë\n",
    "# ‚ïë    \"workspace\" ‚Äî use only locally indexed PDFs              ‚ïë\n",
    "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "SEARCH_MODE    = \"workspace\"       # ‚Üê change to \"workspace\" for offline mode\n",
    "\n",
    "RESEARCH_GOAL  = (\n",
    "    \"To accurately predict a protein‚Äôs three-dimensional (3D) structure directly from its amino acid sequence using artificial intelligence, eliminating the need for time-consuming and expensive experimental methods.\"\n",
    ")\n",
    "\n",
    "MAX_ITERATIONS = 3              # max Expansion‚ÜíResearcher loops (online mode only)\n",
    "\n",
    "# ‚îÄ‚îÄ Validate mode ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "assert SEARCH_MODE in (\"online\", \"workspace\"), \\\n",
    "    f\"SEARCH_MODE must be 'online' or 'workspace', got: {SEARCH_MODE!r}\"\n",
    "\n",
    "mode_label = {\n",
    "    \"online\":    \"üåê ONLINE  ‚Äî ArXiv search enabled\",\n",
    "    \"workspace\": \"üíæ WORKSPACE ‚Äî local PDFs only, no internet\",\n",
    "}[SEARCH_MODE]\n",
    "\n",
    "# ‚îÄ‚îÄ Initial state ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "initial_state: AgentState = {\n",
    "    \"goal\":           RESEARCH_GOAL,\n",
    "    \"vdb\":            vdb,\n",
    "    \"search_mode\":    SEARCH_MODE,\n",
    "    \"current_agent\":  \"Planner\",\n",
    "    \"next_agent\":     \"Planner\",\n",
    "    \"iterations\":     0,\n",
    "    \"max_iterations\": MAX_ITERATIONS,\n",
    "    \"future_ideas\":   [],\n",
    "    \"trace\":          [],\n",
    "}\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(f\"MODE  : {mode_label}\")\n",
    "print(f\"GOAL  : {RESEARCH_GOAL}\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# ‚îÄ‚îÄ Execute ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "result = graph.invoke(initial_state)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"RUN COMPLETE\")\n",
    "print(\"=\" * 65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dafc5c9",
   "metadata": {},
   "source": [
    "## 12. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5qg196qnyvv",
   "metadata": {},
   "source": [
    "## 12b. Full Autonomous Research Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a66twxzxdig",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "  AUTONOMOUS RESEARCH REPORT\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "  Mode  : üíæ WORKSPACE ‚Äî local PDFs only\n",
      "  Goal  : To accurately predict a protein‚Äôs three-dimensional (3D) structure directly from its amino acid sequence using artificial intelligence, eliminating the need for time-consuming and expensive experimental methods.\n",
      "\n",
      "üìç EXECUTION TRACE\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   Planner -> Researcher\n",
      "   Researcher -> Evaluator\n",
      "   Evaluator -> Expansion\n",
      "   Expansion -> END\n",
      "\n",
      "üß† PLANNER ‚Äî Sub-Questions\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   1. Conduct a literature survey of state-of-the-art protein structure prediction methods (e.g., AlphaFold, RoseTold, trRosetta) to identify gaps and opportunities for improvement.\n",
      "   2. Assemble and curate a high-quality dataset of protein sequences with corresponding experimentally determined 3D structures; apply redundancy reduction and split into training/validation/test sets with careful leakage prevention.\n",
      "   3. Design a data representation and encoding scheme for protein sequences and structures (e.g., sequence embeddings, MSA-derived features, pairwise distance maps, torsion angles, graphs or 3D coordinate frames).\n",
      "   4. Propose and prototype AI model architectures suitable for structure prediction (e.g., transformer-based sequence models with geometric reasoning, graph neural networks, diffusion-based coordinate prediction) and define output representations (coordinates, distance constraints, or torsion angles).\n",
      "   5. Define loss functions and training objectives that align with 3D structural accuracy (RMSD, TM-score, GDT-TS, lDDT) and enforce physical plausibility (bond lengths, angles, steric clash penalties).\n",
      "   6. Establish robust evaluation protocols including cross-validation, blind test on novel folds, and metrics for global and local structural quality; implement baselines for comparison.\n",
      "   7. Develop data pipelines and software tooling for data preprocessing, model training, evaluation, and result tracking; ensure reproducibility via versioning, seed control, and documentation.\n",
      "   8. Plan computational resource needs (GPUs/TPUs, storage, parallelization) and cost estimates; explore efficient training strategies (mixed precision, gradient checkpointing, distributed training).\n",
      "   9. Assess ethical, safety, and regulatory considerations; establish responsible-use guidelines and data provenance practices; ensure alignment with community standards.\n",
      "   10. Create a phased research roadmap with milestones, success criteria, and risk mitigation strategies; define a plan for publication, open-source release, or collaboration with experimental groups as appropriate.\n",
      "\n",
      "üîç RESEARCHER ‚Äî Grounded Answer\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   Insufficient evidence.\n",
      "\n",
      "üîç RESEARCHER ‚Äî Sources Retrieved\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   [p.0]  agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf\n",
      "   [p.2]  agent_workspace/papers_local/2602.17888v1.pdf\n",
      "   [p.57]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.35]  agent_workspace/papers_local/2602.17888v1.pdf\n",
      "   [p.4]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.5]  agent_workspace/papers_arxiv/2411.18583v1.pdf\n",
      "   [p.0]  agent_workspace/papers_arxiv/2411.18583v1.pdf\n",
      "   [p.1]  agent_workspace/papers_arxiv/2411.18583v1.pdf\n",
      "   [p.14]  agent_workspace/papers_local/2602.17888v1.pdf\n",
      "   [p.30]  agent_workspace/papers_local/2602.17888v1.pdf\n",
      "   [p.9]  agent_workspace/papers_arxiv/2503.16581v1.pdf\n",
      "   [p.4]  agent_workspace/papers_arxiv/2503.16581v1.pdf\n",
      "   [p.13]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.6]  agent_workspace/papers_arxiv/2503.16581v1.pdf\n",
      "   [p.22]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.18]  agent_workspace/papers_local/2602.17888v1.pdf\n",
      "   [p.21]  agent_workspace/papers_arxiv/2510.22344v1.pdf\n",
      "   [p.21]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.1]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.15]  agent_workspace/papers_arxiv/2502.13957v2.pdf\n",
      "   [p.2]  agent_workspace/papers_arxiv/2309.02144v1.pdf\n",
      "   [p.20]  agent_workspace/papers_arxiv/2510.22344v1.pdf\n",
      "   [p.15]  agent_workspace/papers_arxiv/2309.02144v1.pdf\n",
      "   [p.7]  agent_workspace/papers_arxiv/2309.02144v1.pdf\n",
      "   [p.14]  agent_workspace/papers_arxiv/2309.02144v1.pdf\n",
      "   [p.0]  agent_workspace/papers_arxiv/2309.02144v1.pdf\n",
      "   [p.17]  agent_workspace/papers_arxiv/2309.02144v1.pdf\n",
      "   [p.10]  agent_workspace/papers_arxiv/2510.22344v1.pdf\n",
      "   [p.35]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.32]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.27]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.6]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.9]  agent_workspace/papers_local/2602.17888v1.pdf\n",
      "   [p.34]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.16]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.52]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.5]  agent_workspace/papers_arxiv/2502.13957v2.pdf\n",
      "   [p.8]  agent_workspace/papers_arxiv/2502.13957v2.pdf\n",
      "   [p.37]  agent_workspace/papers_local/2602.17888v1.pdf\n",
      "   [p.49]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.46]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.59]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.0]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.5]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "   [p.58]  agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "\n",
      "üß™ EVALUATOR ‚Äî Quality Assessment\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   Confidence  : 0.58  [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë]\n",
      "   Missing     :\n",
      "     ‚Ä¢ insufficient vector evidence for goal coverage\n",
      "   Routing     : ‚Üí Expansion\n",
      "\n",
      "üöÄ EXPANSION ‚Äî Explorer / Innovator\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   Mode             : workspace\n",
      "   (no internet access ‚Äî workspace mode)\n",
      "   Saturated        : True\n",
      "\n",
      "üí° FUTURE RESEARCH IDEAS\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   1. Develop a hybrid model that combines a protein language model\n",
      "      encoder with a differentiable geometric decoder and physics-\n",
      "      informed refinements to ensure physically plausible 3D\n",
      "      coordinates.\n",
      "   2. Leverage large, diverse protein structure datasets and unlabeled\n",
      "      sequences, including membrane proteins and complexes, with self-\n",
      "      supervised pretraining and multimodal data.\n",
      "   3. Use teacher-student distillation from high-accuracy structure\n",
      "      predictors to bootstrap a scalable predictor while retaining\n",
      "      uncertainty estimates.\n",
      "   4. Predict distance maps and torsion angles in addition to\n",
      "      coordinates, and enforce consistency with a differentiable 3D\n",
      "      coordinate solver.\n",
      "   5. Incorporate uncertainty estimation and calibration, providing per-\n",
      "      residue confidence scores and global structure reliability to\n",
      "      guide refinement.\n",
      "   6. Implement active learning to identify sequences that maximize\n",
      "      coverage of structure space, and generate synthetic data to fill\n",
      "      gaps.\n",
      "   7. Define a formal vector-space coverage metric for structural\n",
      "      predictions, and monitor coverage across folds, the fold space,\n",
      "      and protein families; drive dataset curation to improve coverage.\n",
      "   8. Add data augmentation by in silico mutagenesis and structure\n",
      "      perturbation within physico-chemical bounds to expand training\n",
      "      distribution.\n",
      "   9. Create an evaluation benchmark with standard structure-diagnostic\n",
      "      metrics (GDT-TS, TM-score, GDT-HA, lDDT) and blind CASP-like tests\n",
      "      to quantify progress.\n",
      "   10. Develop interpretability tools to explain per-residue decisions,\n",
      "      such as attention maps or motif-level attributions linked to known\n",
      "      structural features.\n",
      "   11. Foster reproducibility and collaboration: release datasets,\n",
      "      metrics, and baseline models; ensure licensing and ethical\n",
      "      considerations.\n",
      "   12. Optimize for efficiency to enable scalable online predictions for\n",
      "      large proteins and complexes, including model compression and\n",
      "      hardware acceleration.\n",
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "  SUMMARY\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "   Agent steps    : 4\n",
      "   Unique sources : 8\n",
      "   Confidence     : 0.58\n",
      "   Future ideas   : 12\n",
      "   Data status    : ‚úÖ OK\n",
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "#  FULL AUTONOMOUS RESEARCH REPORT\n",
    "#  Displays every stage of the multi-agent run in a readable format.\n",
    "#  Run this cell after Section 11 (graph.invoke) has completed.\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "SEP  = \"‚ïê\" * 68\n",
    "SEP2 = \"‚îÄ\" * 68\n",
    "\n",
    "def _section(title: str) -> None:\n",
    "    print(f\"\\n{SEP}\")\n",
    "    print(f\"  {title}\")\n",
    "    print(SEP)\n",
    "\n",
    "def _sub(title: str) -> None:\n",
    "    print(f\"\\n{title}\")\n",
    "    print(SEP2)\n",
    "\n",
    "# ‚îÄ‚îÄ 0. Header ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "mode       = result.get(\"search_mode\", \"workspace\")\n",
    "mode_label = \"üåê ONLINE  ‚Äî ArXiv search enabled\" if mode == \"online\" else \"üíæ WORKSPACE ‚Äî local PDFs only\"\n",
    "_section(\"AUTONOMOUS RESEARCH REPORT\")\n",
    "print(f\"  Mode  : {mode_label}\")\n",
    "print(f\"  Goal  : {result.get('goal', 'N/A')}\")\n",
    "\n",
    "# ‚îÄ‚îÄ 1. Insufficient-data warning (shown prominently if triggered) ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if result.get(\"insufficient_data\"):\n",
    "    reason = result.get(\"insufficiency_reason\", \"Unknown.\")\n",
    "    print(f\"\\n{'‚ö†Ô∏è  ' * 17}\")\n",
    "    print(\"  ‚ö†Ô∏è  INSUFFICIENT DATA ‚Äî the system could not gather enough evidence\")\n",
    "    print(f\"  Reason : {reason}\")\n",
    "    if mode == \"online\":\n",
    "        print(\"\\n  Suggestions:\")\n",
    "        print(\"    ‚Ä¢ Rephrase RESEARCH_GOAL with more specific terminology\")\n",
    "        print(\"    ‚Ä¢ Add relevant PDFs to ./agent_workspace/papers_local/\")\n",
    "        print(\"    ‚Ä¢ Increase max_results in expansion_agent (currently 4)\")\n",
    "        print(\"    ‚Ä¢ Check internet connection (ArXiv requires network access)\")\n",
    "    else:\n",
    "        print(\"\\n  Suggestions:\")\n",
    "        print(\"    ‚Ä¢ Add PDFs to ./agent_workspace/papers_local/ and re-run Section 10\")\n",
    "        print(\"    ‚Ä¢ Switch SEARCH_MODE = 'online' to let the agent fetch papers\")\n",
    "    print(f\"{'‚ö†Ô∏è  ' * 17}\")\n",
    "\n",
    "# ‚îÄ‚îÄ 2. Execution trace ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "_sub(\"üìç EXECUTION TRACE\")\n",
    "trace = result.get(\"trace\", [])\n",
    "if trace:\n",
    "    for step in trace:\n",
    "        print(f\"   {step}\")\n",
    "else:\n",
    "    print(\"   (no trace recorded)\")\n",
    "\n",
    "# ‚îÄ‚îÄ 3. Planner ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "_sub(\"üß† PLANNER ‚Äî Sub-Questions\")\n",
    "subtasks = result.get(\"planner\", {}).get(\"subtasks\", [])\n",
    "if subtasks:\n",
    "    for i, t in enumerate(subtasks, 1):\n",
    "        print(f\"   {i}. {t}\")\n",
    "else:\n",
    "    print(\"   (no subtasks generated)\")\n",
    "\n",
    "# ‚îÄ‚îÄ 4. Researcher ‚Äî answer ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "_sub(\"üîç RESEARCHER ‚Äî Grounded Answer\")\n",
    "answer = result.get(\"final_answer\", \"\")\n",
    "if answer:\n",
    "    # Word-wrap at ~70 chars for readability\n",
    "    import textwrap\n",
    "    for line in textwrap.wrap(answer, width=70):\n",
    "        print(f\"   {line}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  No answer produced ‚Äî evidence was unavailable.\")\n",
    "\n",
    "# ‚îÄ‚îÄ 5. Researcher ‚Äî sources ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "_sub(\"üîç RESEARCHER ‚Äî Sources Retrieved\")\n",
    "sources = result.get(\"final_sources\", [])\n",
    "if sources:\n",
    "    seen = set()\n",
    "    for s in sources:\n",
    "        key = (s.get(\"source\", \"unknown\"), s.get(\"page\", \"?\"))\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            print(f\"   [p.{s.get('page','?')}]  {s.get('source','unknown')}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  No sources retrieved.\")\n",
    "\n",
    "# ‚îÄ‚îÄ 6. Evaluator ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "ev = result.get(\"evaluator\", {})\n",
    "if ev:\n",
    "    _sub(\"üß™ EVALUATOR ‚Äî Quality Assessment\")\n",
    "    conf = ev.get(\"confidence\")\n",
    "    bar_len = int((conf or 0) * 20)\n",
    "    bar = \"‚ñà\" * bar_len + \"‚ñë\" * (20 - bar_len)\n",
    "    print(f\"   Confidence  : {conf:.2f}  [{bar}]\")\n",
    "    missing = ev.get(\"missing_aspects\", [])\n",
    "    if missing:\n",
    "        print(\"   Missing     :\")\n",
    "        for m in missing:\n",
    "            print(f\"     ‚Ä¢ {m}\")\n",
    "    else:\n",
    "        print(\"   Missing     : (none ‚Äî answer fully covers the goal)\")\n",
    "    print(f\"   Routing     : ‚Üí {ev.get('next_agent', 'N/A')}\")\n",
    "\n",
    "# ‚îÄ‚îÄ 7. Expansion ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "ex = result.get(\"expansion\", {})\n",
    "if ex:\n",
    "    _sub(\"üöÄ EXPANSION ‚Äî Explorer / Innovator\")\n",
    "    exp_mode = ex.get(\"mode\", mode)\n",
    "    print(f\"   Mode             : {exp_mode}\")\n",
    "    if exp_mode == \"online\":\n",
    "        print(f\"   ArXiv query      : {ex.get('query', 'N/A')}\")\n",
    "        print(f\"   Papers downloaded: {ex.get('papers_downloaded', 0)}\")\n",
    "        print(f\"   Chunks indexed   : {ex.get('chunks_added', 0)}\")\n",
    "    else:\n",
    "        print(\"   (no internet access ‚Äî workspace mode)\")\n",
    "    print(f\"   Saturated        : {ex.get('saturated', True)}\")\n",
    "\n",
    "# ‚îÄ‚îÄ 8. Future research ideas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "ideas = result.get(\"future_ideas\", [])\n",
    "if ideas:\n",
    "    label = (\n",
    "        \"üí° FUTURE RESEARCH IDEAS  ‚ö†Ô∏è  (from LLM knowledge ‚Äî no paper evidence)\"\n",
    "        if result.get(\"insufficient_data\")\n",
    "        else \"üí° FUTURE RESEARCH IDEAS\"\n",
    "    )\n",
    "    _sub(label)\n",
    "    for i, idea in enumerate(ideas, 1):\n",
    "        import textwrap\n",
    "        wrapped = textwrap.wrap(idea, width=66)\n",
    "        print(f\"   {i}. {wrapped[0]}\")\n",
    "        for cont in wrapped[1:]:\n",
    "            print(f\"      {cont}\")\n",
    "\n",
    "# ‚îÄ‚îÄ 9. Summary footer ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "_section(\"SUMMARY\")\n",
    "total_steps   = len(trace)\n",
    "total_sources = len({s.get(\"source\",\"\") for s in sources})\n",
    "total_ideas   = len(ideas)\n",
    "conf_val      = ev.get(\"confidence\", 0.0) if ev else 0.0\n",
    "print(f\"   Agent steps    : {total_steps}\")\n",
    "print(f\"   Unique sources : {total_sources}\")\n",
    "print(f\"   Confidence     : {conf_val:.2f}\")\n",
    "print(f\"   Future ideas   : {total_ideas}\")\n",
    "print(f\"   Data status    : {'‚ö†Ô∏è  INSUFFICIENT' if result.get('insufficient_data') else '‚úÖ OK'}\")\n",
    "print(f\"\\n{SEP}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i2ec4p2etuh",
   "metadata": {},
   "source": [
    "## 12c. Research Brief ‚Äî What Was Found & What Are the Limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "s7pyaij0px",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "RESEARCH BRIEF\n",
      "\n",
      "Goal\n",
      "To accurately predict a protein‚Äôs 3D structure directly from its amino acid sequence using AI, reducing reliance on experimental methods.\n",
      "\n",
      "Key Findings\n",
      "- The current evidence presented is insufficient to confirm progress toward the stated goal; evaluator notes insufficient vector evidence for goal coverage (confidence ~0.58).\n",
      "- The discourse references state-of-the-art methods (e.g., AlphaFold, RoseTold, trRosetta) and broad AI-design ideas, but no concrete, validated results or datasets were demonstrated in this run.\n",
      "- A wide range of future-oriented directions is proposed (hybrid models, self-supervised pretraining, uncertainty estimation, distance/torsion representations, differentiable geometry, active learning), indicating potential paths without proven implementations.\n",
      "\n",
      "Limitations\n",
      "- Insufficient vector evidence for goal coverage; moderate evaluator confidence signals incomplete grounding.\n",
      "- No concrete datasets, leakage-prevented splits, training setups, evaluation protocols, or baselines were provided.\n",
      "- Gaps highlighted include dataset curation, reproducibility plans, governance of ethics/safety, and formal evaluation pipelines.\n",
      "\n",
      "Future Directions\n",
      "- Develop a hybrid model combining a protein language model encoder with a differentiable geometric decoder and physics-informed refinements.\n",
      "- Scale using diverse, unlabeled sequence data plus multimodal structure data; apply self-supervised pretraining, uncertainty estimation, and active learning to broaden coverage.\n",
      "- Establish standardized benchmarks and release datasets, metrics (e.g., GDT-TS, TM-score, GDT-HA, lDDT), baselines, and reproducible workflows; pursue blind CASP-like evaluations and collaboration with experimental groups.\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "#  RESEARCH BRIEF\n",
    "#  Uses the LLM to write a concise brief covering:\n",
    "#    1. What the research found (key findings)\n",
    "#    2. Limitations (evidence gaps, missing aspects, data quality)\n",
    "#  Falls back to a rule-based brief if LLM is unavailable.\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "_brief_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a senior research analyst. Based on the autonomous research run below,\n",
    "write a concise research brief in plain English. Do NOT use JSON.\n",
    "\n",
    "‚îÄ‚îÄ‚îÄ RESEARCH INPUT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Goal        : {goal}\n",
    "Sub-questions: {subtasks}\n",
    "\n",
    "‚îÄ‚îÄ‚îÄ AGENT OUTPUTS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Grounded Answer (from Researcher Agent):\n",
    "{answer}\n",
    "\n",
    "Sources used: {num_sources} document(s)\n",
    "Evaluator confidence score: {confidence}\n",
    "Missing aspects flagged by Evaluator: {missing}\n",
    "\n",
    "Future research ideas (from Expansion Agent, if any): {ideas}\n",
    "\n",
    "‚îÄ‚îÄ‚îÄ INSTRUCTIONS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Write the brief in exactly this structure ‚Äî keep each section short and factual:\n",
    "\n",
    "**RESEARCH BRIEF**\n",
    "\n",
    "**Goal**\n",
    "One sentence restating what the research was trying to find out.\n",
    "\n",
    "**Key Findings**\n",
    "2‚Äì4 bullet points summarising what the agents actually found, grounded\n",
    "in the retrieved evidence. If evidence was weak, say so honestly.\n",
    "\n",
    "**Limitations**\n",
    "2‚Äì4 bullet points on what is missing, uncertain, or poorly evidenced ‚Äî\n",
    "draw from the evaluator's missing aspects and confidence score.\n",
    "\n",
    "**Future Directions**\n",
    "1‚Äì3 bullet points on what should be explored next (use the ideas list\n",
    "if available, otherwise infer from the limitations).\n",
    "\n",
    "Keep the entire brief under 300 words.\"\"\"\n",
    ")\n",
    "\n",
    "# ‚îÄ‚îÄ Collect inputs from `result` ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "_goal       = result.get(\"goal\", \"N/A\")\n",
    "_subtasks   = result.get(\"planner\", {}).get(\"subtasks\", [])\n",
    "_answer     = result.get(\"final_answer\", \"No answer was produced.\")\n",
    "_sources    = result.get(\"final_sources\", [])\n",
    "_ev         = result.get(\"evaluator\", {})\n",
    "_confidence = _ev.get(\"confidence\", 0.0) if _ev else 0.0\n",
    "_missing    = _ev.get(\"missing_aspects\", []) if _ev else []\n",
    "_ideas      = result.get(\"future_ideas\", [])\n",
    "\n",
    "# ‚îÄ‚îÄ Generate brief via LLM ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "SEP = \"‚ïê\" * 68\n",
    "\n",
    "if llm is not None:\n",
    "    brief_chain = _brief_prompt | llm\n",
    "    _result     = brief_chain.invoke({\n",
    "        \"goal\":        _goal,\n",
    "        \"subtasks\":    \"\\n\".join(f\"  ‚Ä¢ {t}\" for t in _subtasks) or \"  (none)\",\n",
    "        \"answer\":      _answer[:2000],\n",
    "        \"num_sources\": len(_sources),\n",
    "        \"confidence\":  f\"{_confidence:.2f}\",\n",
    "        \"missing\":     \"\\n\".join(f\"  ‚Ä¢ {m}\" for m in _missing) or \"  (none flagged)\",\n",
    "        \"ideas\":       \"\\n\".join(f\"  ‚Ä¢ {i}\" for i in _ideas)   or \"  (none generated)\",\n",
    "    })\n",
    "    brief_text = _result.content.strip() if hasattr(_result, \"content\") else str(_result).strip()\n",
    "else:\n",
    "    # ‚îÄ‚îÄ Rule-based fallback (no LLM) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    brief_text = (\n",
    "        \"**RESEARCH BRIEF**\\n\\n\"\n",
    "        f\"**Goal**\\n{_goal}\\n\\n\"\n",
    "        \"**Key Findings**\\n\"\n",
    "        + (\"\\n\".join(f\"  ‚Ä¢ {_answer[:300]}...\") if _answer else \"  ‚Ä¢ No findings ‚Äî evidence unavailable.\\n\")\n",
    "        + \"\\n\\n**Limitations**\\n\"\n",
    "        + (\"\\n\".join(f\"  ‚Ä¢ {m}\" for m in _missing) if _missing else \"  ‚Ä¢ Confidence too low to draw conclusions.\\n\")\n",
    "        + f\"\\n  ‚Ä¢ Confidence score: {_confidence:.2f} (below threshold)\\n\"\n",
    "        + f\"  ‚Ä¢ Only {len(_sources)} source(s) retrieved.\\n\\n\"\n",
    "        \"**Future Directions**\\n\"\n",
    "        + (\"\\n\".join(f\"  ‚Ä¢ {i}\" for i in _ideas) if _ideas else \"  ‚Ä¢ Switch to online mode and expand paper corpus.\\n\")\n",
    "    )\n",
    "\n",
    "# ‚îÄ‚îÄ Print ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(f\"\\n{SEP}\")\n",
    "print(brief_text)\n",
    "print(f\"{SEP}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "047cdc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "MODE : üíæ WORKSPACE\n",
      "=================================================================\n",
      "\n",
      "EXECUTION TRACE\n",
      "----------------------------------------\n",
      " ‚Ä¢ Planner -> Researcher\n",
      " ‚Ä¢ Researcher -> Evaluator\n",
      " ‚Ä¢ Evaluator -> Expansion\n",
      " ‚Ä¢ Expansion -> END\n",
      "\n",
      "PLANNER ‚Äî SUB-QUESTIONS\n",
      "----------------------------------------\n",
      "  1. Conduct a literature survey of state-of-the-art protein structure prediction methods (e.g., AlphaFold, RoseTold, trRosetta) to identify gaps and opportunities for improvement.\n",
      "  2. Assemble and curate a high-quality dataset of protein sequences with corresponding experimentally determined 3D structures; apply redundancy reduction and split into training/validation/test sets with careful leakage prevention.\n",
      "  3. Design a data representation and encoding scheme for protein sequences and structures (e.g., sequence embeddings, MSA-derived features, pairwise distance maps, torsion angles, graphs or 3D coordinate frames).\n",
      "  4. Propose and prototype AI model architectures suitable for structure prediction (e.g., transformer-based sequence models with geometric reasoning, graph neural networks, diffusion-based coordinate prediction) and define output representations (coordinates, distance constraints, or torsion angles).\n",
      "  5. Define loss functions and training objectives that align with 3D structural accuracy (RMSD, TM-score, GDT-TS, lDDT) and enforce physical plausibility (bond lengths, angles, steric clash penalties).\n",
      "  6. Establish robust evaluation protocols including cross-validation, blind test on novel folds, and metrics for global and local structural quality; implement baselines for comparison.\n",
      "  7. Develop data pipelines and software tooling for data preprocessing, model training, evaluation, and result tracking; ensure reproducibility via versioning, seed control, and documentation.\n",
      "  8. Plan computational resource needs (GPUs/TPUs, storage, parallelization) and cost estimates; explore efficient training strategies (mixed precision, gradient checkpointing, distributed training).\n",
      "  9. Assess ethical, safety, and regulatory considerations; establish responsible-use guidelines and data provenance practices; ensure alignment with community standards.\n",
      "  10. Create a phased research roadmap with milestones, success criteria, and risk mitigation strategies; define a plan for publication, open-source release, or collaboration with experimental groups as appropriate.\n",
      "\n",
      "RESEARCHER ‚Äî GROUNDED ANSWER\n",
      "----------------------------------------\n",
      "Insufficient evidence.\n",
      "\n",
      "RESEARCHER ‚Äî SOURCES\n",
      "  [p.0] agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf\n",
      "  [p.0] agent_workspace/papers_local/AI_Early_Disease_Detection_Research_Paper.pdf\n",
      "  [p.2] agent_workspace/papers_local/2602.17888v1.pdf\n",
      "  [p.2] agent_workspace/papers_local/2602.17888v1.pdf\n",
      "  [p.57] agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "  [p.35] agent_workspace/papers_local/2602.17888v1.pdf\n",
      "  [p.4] agent_workspace/papers_arxiv/2601.05264v1.pdf\n",
      "  [p.5] agent_workspace/papers_arxiv/2411.18583v1.pdf\n",
      "  [p.0] agent_workspace/papers_arxiv/2411.18583v1.pdf\n",
      "  [p.0] agent_workspace/papers_arxiv/2411.18583v1.pdf\n",
      "\n",
      "EVALUATOR\n",
      "----------------------------------------\n",
      "  Confidence  : 0.5786653304007049\n",
      "  Missing     : ['insufficient vector evidence for goal coverage']\n",
      "\n",
      "EXPANSION\n",
      "----------------------------------------\n",
      "  Mode             : workspace\n",
      "  (no internet access ‚Äî workspace mode)\n",
      "  Saturated        : True\n",
      "\n",
      "FUTURE RESEARCH IDEAS\n",
      "----------------------------------------\n",
      "  1. Develop a hybrid model that combines a protein language model encoder with a differentiable geometric decoder and physics-informed refinements to ensure physically plausible 3D coordinates.\n",
      "  2. Leverage large, diverse protein structure datasets and unlabeled sequences, including membrane proteins and complexes, with self-supervised pretraining and multimodal data.\n",
      "  3. Use teacher-student distillation from high-accuracy structure predictors to bootstrap a scalable predictor while retaining uncertainty estimates.\n",
      "  4. Predict distance maps and torsion angles in addition to coordinates, and enforce consistency with a differentiable 3D coordinate solver.\n",
      "  5. Incorporate uncertainty estimation and calibration, providing per-residue confidence scores and global structure reliability to guide refinement.\n",
      "  6. Implement active learning to identify sequences that maximize coverage of structure space, and generate synthetic data to fill gaps.\n",
      "  7. Define a formal vector-space coverage metric for structural predictions, and monitor coverage across folds, the fold space, and protein families; drive dataset curation to improve coverage.\n",
      "  8. Add data augmentation by in silico mutagenesis and structure perturbation within physico-chemical bounds to expand training distribution.\n",
      "  9. Create an evaluation benchmark with standard structure-diagnostic metrics (GDT-TS, TM-score, GDT-HA, lDDT) and blind CASP-like tests to quantify progress.\n",
      "  10. Develop interpretability tools to explain per-residue decisions, such as attention maps or motif-level attributions linked to known structural features.\n",
      "  11. Foster reproducibility and collaboration: release datasets, metrics, and baseline models; ensure licensing and ethical considerations.\n",
      "  12. Optimize for efficiency to enable scalable online predictions for large proteins and complexes, including model compression and hardware acceleration.\n"
     ]
    }
   ],
   "source": [
    "ex   = result.get(\"expansion\", {})\n",
    "mode = result.get(\"search_mode\", \"workspace\")\n",
    "\n",
    "# ‚îÄ‚îÄ Header ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"=\" * 65)\n",
    "print(f\"MODE : {'üåê ONLINE' if mode == 'online' else 'üíæ WORKSPACE'}\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# ‚îÄ‚îÄ Insufficient data warning ‚Äî shown first if triggered ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if result.get(\"insufficient_data\"):\n",
    "    reason = result.get(\"insufficiency_reason\", \"Unknown reason.\")\n",
    "    print(\"\\n\" + \"‚ö†Ô∏è \" * 20)\n",
    "    print(\"  INSUFFICIENT DATA ‚Äî the system could not gather enough evidence\")\n",
    "    print(\"  Reason  :\", reason)\n",
    "    print()\n",
    "    if mode == \"online\":\n",
    "        print(\"  Suggestions:\")\n",
    "        print(\"    1. Rephrase RESEARCH_GOAL with more specific or standard terminology\")\n",
    "        print(\"    2. Add relevant PDFs manually to ./agent_workspace/papers_local/\")\n",
    "        print(\"       then re-run Section 10 to index them\")\n",
    "        print(\"    3. Increase max_results in expansion_agent (currently 4)\")\n",
    "        print(\"    4. Check your internet connection (ArXiv requires network access)\")\n",
    "    else:\n",
    "        print(\"  Suggestions:\")\n",
    "        print(\"    1. Add PDFs to ./agent_workspace/papers_local/ and re-run Section 10\")\n",
    "        print(\"    2. Switch to SEARCH_MODE = 'online' to let the agent fetch papers\")\n",
    "    print(\"‚ö†Ô∏è \" * 20)\n",
    "\n",
    "# ‚îÄ‚îÄ Execution trace ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\nEXECUTION TRACE\")\n",
    "print(\"-\" * 40)\n",
    "for step in result.get(\"trace\", []):\n",
    "    print(\" ‚Ä¢\", step)\n",
    "\n",
    "# ‚îÄ‚îÄ Planner output ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\nPLANNER ‚Äî SUB-QUESTIONS\")\n",
    "print(\"-\" * 40)\n",
    "for i, t in enumerate(result.get(\"planner\", {}).get(\"subtasks\", []), 1):\n",
    "    print(f\"  {i}. {t}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Researcher output ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\nRESEARCHER ‚Äî GROUNDED ANSWER\")\n",
    "print(\"-\" * 40)\n",
    "answer = result.get(\"final_answer\", \"\")\n",
    "if answer:\n",
    "    print(answer)\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  No answer produced ‚Äî evidence was unavailable.\")\n",
    "\n",
    "print(\"\\nRESEARCHER ‚Äî SOURCES\")\n",
    "sources = result.get(\"final_sources\", [])\n",
    "if sources:\n",
    "    for s in sources[:10]:\n",
    "        print(f\"  [p.{s.get('page', '?')}] {s.get('source', 'unknown')}\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  No sources retrieved.\")\n",
    "\n",
    "# ‚îÄ‚îÄ Evaluator output ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "ev = result.get(\"evaluator\", {})\n",
    "if ev:\n",
    "    print(\"\\nEVALUATOR\")\n",
    "    print(\"-\" * 40)\n",
    "    conf = ev.get(\"confidence\", None)\n",
    "    print(f\"  Confidence  : {conf if conf is not None else 'N/A'}\")\n",
    "    print(f\"  Missing     : {ev.get('missing_aspects', [])}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Expansion output ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if ex:\n",
    "    print(\"\\nEXPANSION\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  Mode             : {ex.get('mode', mode)}\")\n",
    "    if ex.get(\"mode\") == \"online\":\n",
    "        print(f\"  ArXiv query      : {ex.get('query', 'N/A')}\")\n",
    "        print(f\"  Papers downloaded: {ex.get('papers_downloaded', 0)}\")\n",
    "        print(f\"  Chunks indexed   : {ex.get('chunks_added', 0)}\")\n",
    "    else:\n",
    "        print(\"  (no internet access ‚Äî workspace mode)\")\n",
    "    print(f\"  Saturated        : {ex.get('saturated', True)}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Future ideas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "ideas = result.get(\"future_ideas\", [])\n",
    "label = (\n",
    "    \"FUTURE RESEARCH IDEAS  ‚ö†Ô∏è  (generated from LLM knowledge ‚Äî no paper evidence)\"\n",
    "    if result.get(\"insufficient_data\") else\n",
    "    \"FUTURE RESEARCH IDEAS\"\n",
    ")\n",
    "if ideas:\n",
    "    print(f\"\\n{label}\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, idea in enumerate(ideas, 1):\n",
    "        print(f\"  {i}. {idea}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37587e2",
   "metadata": {},
   "source": [
    "## 13. How to Customise\n",
    "\n",
    "| What | Where |\n",
    "|------|-------|\n",
    "| **Switch mode** | Set `SEARCH_MODE = \"online\"` or `\"workspace\"` in **Section 11** |\n",
    "| Change research goal | `RESEARCH_GOAL` in **Section 11** |\n",
    "| Add local PDFs | Drop files into `./agent_workspace/papers_local/` and re-run **Section 10** |\n",
    "| Swap LLM | Replace `ChatGroq` in **Section 1** with any LangChain `BaseChatModel` |\n",
    "| Add a 5th agent | Define `my_agent(state)`, add to `AGENT_REGISTRY`, any agent can set `next_agent = 'MyAgent'` |\n",
    "| Change online sufficiency | Edit `sufficient = confidence >= 0.75 and len(sources) >= 4` in `evaluator_agent` |\n",
    "| Change workspace sufficiency | Edit `sufficient = (confidence >= 0.50) or (len(sources) >= 2)` in `evaluator_agent` |\n",
    "| More ArXiv papers | Increase `max_results` in `expansion_agent` |\n",
    "\n",
    "---\n",
    "\n",
    "### Mode comparison\n",
    "\n",
    "```\n",
    "ONLINE mode flow:\n",
    "  Planner ‚Üí Researcher(RAG) ‚Üí Evaluator\n",
    "                                  ‚îÇ\n",
    "                          confident? ‚îÄ‚îÄYES‚îÄ‚îÄ‚ñ∫ END\n",
    "                                  ‚îÇ\n",
    "                                  NO\n",
    "                                  ‚îÇ\n",
    "                            Expansion(ArXiv download)\n",
    "                                  ‚îÇ\n",
    "                           new papers? ‚îÄ‚îÄYES‚îÄ‚îÄ‚ñ∫ Researcher (loop)\n",
    "                                  ‚îÇ\n",
    "                                  NO (saturated)\n",
    "                                  ‚îÇ\n",
    "                            generate ideas ‚Üí END\n",
    "\n",
    "WORKSPACE mode flow:\n",
    "  Planner ‚Üí Researcher(RAG) ‚Üí Evaluator\n",
    "                                  ‚îÇ\n",
    "                      any answer? ‚îÄ‚îÄYES‚îÄ‚îÄ‚ñ∫ END\n",
    "                                  ‚îÇ\n",
    "                                  NO (empty DB)\n",
    "                                  ‚îÇ\n",
    "                          Expansion(ideas only) ‚Üí END\n",
    "```\n",
    "\n",
    "### Why the flow is not hard-coded\n",
    "\n",
    "```python\n",
    "# ‚ùå  Hard-coded (bad):  Planner ‚Üí Researcher ‚Üí Evaluator ‚Üí Expansion\n",
    "g.add_edge(\"planner\",    \"researcher\")\n",
    "g.add_edge(\"researcher\", \"evaluator\")\n",
    "g.add_edge(\"evaluator\",  \"expansion\")\n",
    "\n",
    "# ‚úÖ  Dynamic (this notebook): ONE node, data-driven routing\n",
    "g.add_conditional_edges(\"agent_executor\", route, {\"LOOP\": \"agent_executor\", \"END\": END})\n",
    "# Each agent sets state['next_agent'] ‚Üí routing happens at runtime\n",
    "# Mode behaviour is embedded in the agent functions, not in graph edges\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09b6840",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
