{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "76cfbf2c",
      "metadata": {},
      "source": [
        "# `/test` LangGraph Notebook (Prompt-Synced)\n",
        "\n",
        "This notebook defines the LangGraph loop like `autonomous_4_agents_langgraph.ipynb`, but **uses the exact same agent-node implementations and prompts as `/test`** by importing them from `app.agent`.\n",
        "\n",
        "This guarantees prompt parity with the running app.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf731d8a",
      "metadata": {},
      "source": [
        "## 0. Optional Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b23e6a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -q langgraph langchain-core langchain-groq arxiv chromadb sentence-transformers python-dotenv pypdf2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b758fd1c",
      "metadata": {},
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b58be42f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from pprint import pprint\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "from app.agent import (\n",
        "    AgentState,\n",
        "    create_new_session,\n",
        "    planner_agent,\n",
        "    researcher_agent,\n",
        "    evaluator_agent,\n",
        "    expansion_agent,\n",
        "    RESEARCHER_PROMPT,\n",
        "    EVALUATOR_PROMPT,\n",
        "    save_results,\n",
        "    generate_report,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36994c0f",
      "metadata": {},
      "source": [
        "## 2. Prompt Parity Check\n",
        "The prompts below are imported directly from `app.agent`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a3700f",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Researcher prompt (first 400 chars):\")\n",
        "print(RESEARCHER_PROMPT[:400])\n",
        "print(\"\n",
        "Evaluator prompt:\")\n",
        "print(EVALUATOR_PROMPT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9314ab89",
      "metadata": {},
      "source": [
        "## 3. Build Full Graph (in notebook)\n",
        "Graph structure is the same loop used in backend mission execution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68c5e3b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "AGENT_REGISTRY = {\n",
        "    \"Planner\": planner_agent,\n",
        "    \"Researcher\": researcher_agent,\n",
        "    \"Evaluator\": evaluator_agent,\n",
        "    \"Expansion\": expansion_agent,\n",
        "}\n",
        "\n",
        "\n",
        "def agent_executor(state: AgentState) -> AgentState:\n",
        "    current = state.get(\"current_agent\", \"Planner\")\n",
        "    fn = AGENT_REGISTRY.get(current)\n",
        "    if fn is None:\n",
        "        return {\n",
        "            **state,\n",
        "            \"next_agent\": \"END\",\n",
        "            \"current_agent\": \"END\",\n",
        "            \"trace\": state.get(\"trace\", []) + [f\"{current} → UNKNOWN → END\"],\n",
        "        }\n",
        "\n",
        "    update = fn(state)\n",
        "    next_agent = update.get(\"next_agent\", \"END\")\n",
        "    trace = state.get(\"trace\", []) + [f\"{current} → {next_agent}\"]\n",
        "    return {\n",
        "        **state,\n",
        "        **update,\n",
        "        \"current_agent\": next_agent,\n",
        "        \"trace\": trace,\n",
        "    }\n",
        "\n",
        "\n",
        "def route(state: AgentState) -> str:\n",
        "    return \"END\" if state.get(\"next_agent\", \"END\") == \"END\" else \"LOOP\"\n",
        "\n",
        "\n",
        "def build_graph():\n",
        "    g = StateGraph(AgentState)\n",
        "    g.add_node(\"agent_executor\", agent_executor)\n",
        "    g.set_entry_point(\"agent_executor\")\n",
        "    g.add_conditional_edges(\n",
        "        \"agent_executor\",\n",
        "        route,\n",
        "        {\n",
        "            \"LOOP\": \"agent_executor\",\n",
        "            \"END\": END,\n",
        "        },\n",
        "    )\n",
        "    return g.compile()\n",
        "\n",
        "GRAPH = build_graph()\n",
        "print(\"Graph compiled\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "861b02d2",
      "metadata": {},
      "source": [
        "## 4. Prepare Mission State (same shape as `/test` backend)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1445616",
      "metadata": {},
      "outputs": [],
      "source": [
        "topic = \"AI for climate-resilient agriculture\"\n",
        "search_mode = \"online\"  # \"online\" or \"workspace\"\n",
        "max_iterations = 3\n",
        "\n",
        "session_id = create_new_session()\n",
        "\n",
        "events = []\n",
        "tokens = []\n",
        "\n",
        "def on_event(payload: dict):\n",
        "    events.append(payload)\n",
        "    step = payload.get(\"step\", \"\")\n",
        "    status = payload.get(\"status\", \"\")\n",
        "    summary = payload.get(\"summary\", \"\")\n",
        "    if status in {\"running\", \"complete\", \"error\"}:\n",
        "        print(f\"[{step}] {status}: {summary}\")\n",
        "\n",
        "def on_token(step: str, agent: str, token: str):\n",
        "    tokens.append({\"step\": step, \"agent\": agent, \"token\": token})\n",
        "\n",
        "state = {\n",
        "    \"session_id\": session_id,\n",
        "    \"topic\": topic,\n",
        "    \"goal\": topic,\n",
        "    \"search_mode\": search_mode,\n",
        "    \"papers\": [],\n",
        "    \"gaps\": [],\n",
        "    \"weak_gaps\": [],\n",
        "    \"ideas\": [],\n",
        "    \"novelty_scores\": [],\n",
        "    \"evidence_assessment\": {},\n",
        "    \"insufficient_evidence_message\": \"\",\n",
        "    \"insufficient_data\": False,\n",
        "    \"insufficiency_reason\": \"\",\n",
        "    \"current_agent\": \"Planner\",\n",
        "    \"next_agent\": \"Planner\",\n",
        "    \"iterations\": 0,\n",
        "    \"max_iterations\": max_iterations,\n",
        "    \"future_ideas\": [],\n",
        "    \"trace\": [],\n",
        "    \"_emit\": on_event,\n",
        "    \"_token\": on_token,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c430f98",
      "metadata": {},
      "source": [
        "## 5. Run Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3fa8cff",
      "metadata": {},
      "outputs": [],
      "source": [
        "result = GRAPH.invoke(state)\n",
        "result.pop(\"_emit\", None)\n",
        "result.pop(\"_token\", None)\n",
        "\n",
        "print(\"\n",
        "Mission complete\")\n",
        "print(\"Trace:\")\n",
        "for t in result.get(\"trace\", []):\n",
        "    print(\" -\", t)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "089c1dd7",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\n",
        "Summary:\")\n",
        "print(\"papers:\", len(result.get(\"papers\", [])))\n",
        "print(\"strong gaps:\", len(result.get(\"gaps\", [])))\n",
        "print(\"weak gaps:\", len(result.get(\"weak_gaps\", [])))\n",
        "print(\"ideas:\", len(result.get(\"ideas\", [])))\n",
        "print(\"insufficient:\", result.get(\"insufficient_data\", False))\n",
        "print(\"\n",
        "Evidence assessment:\")\n",
        "print(json.dumps(result.get(\"evidence_assessment\", {}), indent=2))\n",
        "\n",
        "if result.get(\"ideas\"):\n",
        "    print(\"\n",
        "First idea:\")\n",
        "    pprint(result[\"ideas\"][0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8dc8396",
      "metadata": {},
      "source": [
        "## 6. Save Session Output + Generate Report\n",
        "Uses the same save/report helpers as backend.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbec5923",
      "metadata": {},
      "outputs": [],
      "source": [
        "save_update, save_event = save_results(result)\n",
        "result.update(save_update)\n",
        "print(save_event.get(\"summary\", \"Saved\"))\n",
        "print(\"Output file:\", result.get(\"output_file\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "708642cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "report_md = generate_report(result)\n",
        "print(report_md[:3000])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f3e254d",
      "metadata": {},
      "source": [
        "## 7. Inspect Stream Events/Tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc054443",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Event count:\", len(events))\n",
        "print(\"Token chunks:\", len(tokens))\n",
        "print(\"\n",
        "Last 5 events:\")\n",
        "for ev in events[-5:]:\n",
        "    print(json.dumps(ev, ensure_ascii=False)[:400])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
